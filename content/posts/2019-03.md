---
title: "March, 2019"
date: 2019-03-01T12:16:30+01:00
author: "Alan Orth"
tags: ["Notes"]
---

## 2019-03-01

- I checked IITA's 259 Feb 14 records from last month for duplicates using Atmire's Duplicate Checker on a fresh snapshot of CGSpace on my local machine and everything looks good
- I am now only waiting to hear from her about where the items should go, though I assume Journal Articles go to IITA Journal Articles collection, etc...
- Looking at the other half of Udana's WLE records from 2018-11
  - I finished the ones for Restoring Degraded Landscapes (RDL), but these are for Variability, Risks and Competing Uses (VRC)
  - I did the usual cleanups for whitespace, added regions where they made sense for certain countries, cleaned up the DOI link formats, added rights information based on the publications page for a few items
  - Most worryingly, there are encoding errors in the abstracts for eleven items, for example:
  - 68.15% � 9.45 instead of 68.15% ± 9.45
  - 2003�2013 instead of 2003–2013
- I think I will need to ask Udana to re-copy and paste the abstracts with more care using Google Docs

<!--more-->

## 2019-03-03

- Trying to finally upload IITA's 259 Feb 14 items to CGSpace so I exported them from DSpace Test:

```
$ mkdir 2019-03-03-IITA-Feb14
$ dspace export -i 10568/108684 -t COLLECTION -m -n 0 -d 2019-03-03-IITA-Feb14
```

- As I was inspecting the archive I noticed that there were some problems with the bitsreams:
  - First, Sisay didn't include the bitstream descriptions
  - Second, only five items had bitstreams and I remember in the discussion with IITA that there should have been nine!
  - I had to refer to the original CSV from January to find the file names, then download and add them to the export contents manually!
- After adding the missing bitstreams and descriptions manually I tested them again locally, then imported them to a temporary collection on CGSpace:

```
$ dspace import -a -c 10568/99832 -e aorth@stfu.com -m 2019-03-03-IITA-Feb14.map -s /tmp/2019-03-03-IITA-Feb14
```

- DSpace's export function doesn't include the collections for some reason, so you need to import them somewhere first, then export the collection metadata and re-map the items to proper owning collections based on their types using OpenRefine or something
- After re-importing to CGSpace to apply the mappings, I deleted the collection on DSpace Test and ran the `dspace cleanup` script
- Merge the IITA research theme changes from last month to the `5_x-prod` branch ([#413](https://github.com/ilri/DSpace/pull/413))
  - I will deploy to CGSpace soon and then think about how to batch tag all IITA's existing items with this metadata
- Deploy Tomcat 7.0.93 on CGSpace (linode18) after having tested it on DSpace Test (linode19) for a week

## 2019-03-06

- Abenet was having problems with a CIP user account, I think that the user could not register
- I suspect it's related to the email issue that ICT hasn't responded about since last week
- As I thought, I still cannot send emails from CGSpace:

```
$ dspace test-email

About to send test email:
 - To: blah@stfu.com
 - Subject: DSpace test email
 - Server: smtp.office365.com

Error sending email:
 - Error: javax.mail.AuthenticationFailedException
```

- I will send a follow-up to ICT to ask them to reset the password

## 2019-03-07

- ICT reset the email password and I confirmed that it is working now
- Generate a controlled vocabulary of 1187 AGROVOC subjects from the top 1500 that I checked last month, dumping the terms themselves using `csvcut` and then applying XML controlled vocabulary format in vim and then checking with tidy for good measure:

```
$ csvcut -c name 2019-02-22-subjects.csv > dspace/config/controlled-vocabularies/dc-contributor-author.xml
$ # apply formatting in XML file
$ tidy -xml -utf8 -iq -m -w 0 dspace/config/controlled-vocabularies/dc-subject.xml
```

- I tested the AGROVOC controlled vocabulary locally and will deploy it on DSpace Test soon so people can see it
- Atmire noticed my message about the "solr_update_time_stamp" error on the dspace-tech mailing list and created an issue on their tracker to discuss it with me
  - They say the error is harmless, but has nevertheless been fixed in their newer module versions

## 2019-03-08

- There's an issue with CGSpace right now where all items are giving a blank page in the XMLUI
  - Interestingly, if I check an item in the REST API it is also mostly blank: only the title and the ID!
  - I don't see anything unusual in the Tomcat logs, though there are thousands of those `solr_update_time_stamp` errors:

```
# journalctl -u tomcat7 | grep -c 'Multiple update components target the same field:solr_update_time_stamp'
1076
```

- I restarted Tomcat and it's OK now...
- Skype meeting with Peter and Abenet and Sisay
  - We want to try to crowd source the correction of invalid AGROVOC terms starting with the ~313 invalid ones from our top 1500
  - We will share a Google Docs spreadsheet with the partners and ask them to mark the deletions and corrections
  - Abenet and Alan to spend some time identifying correct DCTERMS fields to move to, with preference over CG Core 2.0 as we want to be globally compliant (use information from SEO crosswalks)
  - I need to follow up on the privacy page that Sisay worked on
  - We want to try to migrate the 600 [Livestock CRP blog posts](https://livestock.cgiar.org) to CGSpace, Peter will try to export the XML from WordPress so I can try to parse it with a script

## 2019-03-09

- I shared a post on Yammer informing our editors to try to AGROVOC controlled list
- The SPDX legal committee had a meeting and discussed the addition of CC-BY-ND-3.0-IGO and other IGO licenses to their list, but it seems unlikely ([spdx/license-list-XML/issues/767](https://github.com/spdx/license-list-XML/issues/767#issuecomment-470709673))
- The FireOak report highlights the fact that several CGSpace collections have mixed-content errors due to the use of HTTP links in the Feedburner forms
- I see 46 occurrences of these with this query:

```
dspace=# SELECT text_value FROM metadatavalue WHERE resource_type_id in (3,4) AND (text_value LIKE '%http://feedburner.%' OR text_value LIKE '%http://feeds.feedburner.%');
```

- I can replace these globally using the following SQL:

```
dspace=# UPDATE metadatavalue SET text_value = REGEXP_REPLACE(text_value, 'http://feedburner.','https//feedburner.', 'g') WHERE resource_type_id in (3,4) AND text_value LIKE '%http://feedburner.%';
UPDATE 43
dspace=# UPDATE metadatavalue SET text_value = REGEXP_REPLACE(text_value, 'http://feeds.feedburner.','https//feeds.feedburner.', 'g') WHERE resource_type_id in (3,4) AND text_value LIKE '%http://feeds.feedburner.%';
UPDATE 44
```

- I ran the corrections on CGSpace and DSpace Test

## 2019-03-10

- Working on tagging IITA's items with their new research theme (`cg.identifier.iitatheme`) based on their existing IITA subjects (see [notes from 2019-02]({{< relref "2018-02.md" >}}))
- I exported the entire IITA community from CGSpace and then used `csvcut` to extract only the needed fields:

```
$ csvcut -c 'id,cg.subject.iita,cg.subject.iita[],cg.subject.iita[en],cg.subject.iita[en_US]' ~/Downloads/10568-68616.csv > /tmp/iita.csv
```

- After importing to OpenRefine I realized that tagging items based on their subjects is tricky because of the row/record mode of OpenRefine when you split the multi-value cells as well as the fact that some items might need to be tagged twice (thus needing a `||`)

- I think it might actually be easier to filter by IITA subject, then by IITA theme (if needed), and then do transformations with some conditional values in GREL expressions like:

```
if(isBlank(value), 'PLANT PRODUCTION & HEALTH', value + '||PLANT PRODUCTION & HEALTH')
```

- Then it's more annoying because there are four IITA subject columns...
- In total this would add research themes to 1,755 items
- I want to double check one last time with Bosede that they would like to do this, because I also see that this will tag a few hundred items from the 1970s and 1980s

## 2019-03-11

- Bosede said that she would like the IITA research theme tagging only for items since 2015, which would be 256 items

## 2019-03-12

- I imported the changes to 256 of IITA's records on CGSpace

## 2019-03-14

- CGSpace had the same issue with blank items like earlier this month and I restarted Tomcat to fix it
- Create a pull request to change Swaziland to Eswatini and Macedonia to North Macedonia ([#414](https://github.com/ilri/DSpace/pull/414))
  - I see thirty-six items using Swaziland country metadata, and Peter says we should change only those from 2018 and 2019
  - I think that I could get the resource IDs from SQL and then export them using `dspace metadata-export`...
- This is a bit ugly, but it works (using the [DSpace 5 SQL helper function](https://wiki.duraspace.org/display/DSPACE/Helper+SQL+functions+for+DSpace+5) to resolve ID to handle):

```
for id in $(psql -U postgres -d dspacetest -h localhost -c "SELECT resource_id FROM metadatavalue WHERE resource_type_id=2 AND metadata_field_id=228 AND text_value LIKE '%SWAZILAND%'" | grep -oE '[0-9]{3,}'); do

    echo "Getting handle for id: ${id}"

    handle=$(psql -U postgres -d dspacetest -h localhost -c "SELECT ds5_item2itemhandle($id)" | grep -oE '[0-9]{5}/[0-9]+')

    ~/dspace/bin/dspace metadata-export -f /tmp/${id}.csv -i $handle

done
```

- Then I couldn't figure out a clever way to join all the CSVs, so I just grepped them to find the IDs with dates from 2018 and 2019 and there are apparently only three:

```
$ grep -oE '201[89]' /tmp/*.csv | sort -u
/tmp/94834.csv:2018
/tmp/95615.csv:2018
/tmp/96747.csv:2018
```

- And looking at those items more closely, only one of them has an *issue date* of after 2018-04, so I will only update that one (as the countrie's name only changed in 2018-04)
- Run all system updates and reboot linode20
- Follow up with Felix from Earlham to see if he's done testing DSpace Test with COPO so I can re-sync the server from CGSpace

## 2019-03-15

- CGSpace (linode18) has the blank page error again
- I'm not sure if it's related, but I see the following error in DSpace's log:

```
2019-03-15 14:09:32,685 ERROR org.dspace.storage.rdbms.DatabaseManager @ SQL QueryTable Error -
java.sql.SQLException: Connection org.postgresql.jdbc.PgConnection@55ba10b5 is closed.
        at org.apache.tomcat.dbcp.dbcp.DelegatingConnection.checkOpen(DelegatingConnection.java:398)
        at org.apache.tomcat.dbcp.dbcp.DelegatingConnection.prepareStatement(DelegatingConnection.java:279)
        at org.apache.tomcat.dbcp.dbcp.PoolingDataSource$PoolGuardConnectionWrapper.prepareStatement(PoolingDataSource.java:313)
        at org.dspace.storage.rdbms.DatabaseManager.queryTable(DatabaseManager.java:220)
        at org.dspace.authorize.AuthorizeManager.getPolicies(AuthorizeManager.java:612)
        at org.dspace.content.crosswalk.METSRightsCrosswalk.disseminateElement(METSRightsCrosswalk.java:154)
        at org.dspace.content.crosswalk.METSRightsCrosswalk.disseminateElement(METSRightsCrosswalk.java:300)
```

- Interestingly, I see a pattern of these errors increasing, with single and double digit numbers over the past month, but spikes of over 1,000 today, yesterday, and on 2019-03-08, which was exactly the first time we saw this blank page error recently

```
# grep -c 'SQL QueryTable Error' dspace.log.2019-0*
dspace.log.2019-02-01:6
dspace.log.2019-02-02:1
dspace.log.2019-02-03:0
dspace.log.2019-02-04:4
dspace.log.2019-02-05:4
dspace.log.2019-02-06:3
dspace.log.2019-02-07:0
dspace.log.2019-02-08:2
dspace.log.2019-02-09:0
dspace.log.2019-02-10:0
dspace.log.2019-02-11:1
dspace.log.2019-02-12:2
dspace.log.2019-02-13:1
dspace.log.2019-02-14:74
dspace.log.2019-02-15:47
dspace.log.2019-02-16:44
dspace.log.2019-02-17:37
dspace.log.2019-02-18:191
dspace.log.2019-02-19:51
dspace.log.2019-02-20:32
dspace.log.2019-02-21:64
dspace.log.2019-02-22:48
dspace.log.2019-02-23:32
dspace.log.2019-02-24:25
dspace.log.2019-02-25:53
dspace.log.2019-02-26:63
dspace.log.2019-02-27:28
dspace.log.2019-02-28:31
dspace.log.2019-03-01:29
dspace.log.2019-03-02:24
dspace.log.2019-03-03:41
dspace.log.2019-03-04:25
dspace.log.2019-03-05:48
dspace.log.2019-03-06:48
dspace.log.2019-03-07:42
dspace.log.2019-03-08:1781
dspace.log.2019-03-09:22
dspace.log.2019-03-10:23
dspace.log.2019-03-11:52
dspace.log.2019-03-12:474
dspace.log.2019-03-13:37
dspace.log.2019-03-14:924
dspace.log.2019-03-15:770
```

- There are not too many connections currently in PostgreSQL:

```
$ psql -c 'select * from pg_stat_activity' | grep -o -E '(dspaceWeb|dspaceApi|dspaceCli)' | sort | uniq -c
      6 dspaceApi
     10 dspaceCli
     15 dspaceWeb
```

- I didn't see anything interesting in the PostgreSQL logs, though this stack trace from the Tomcat logs (in the systemd journal) from earlier today *might* be related?

```
SEVERE: Servlet.service() for servlet [spring] in context with path [] threw exception [org.springframework.web.util.NestedServletException: Request processing failed; nested exception is java.util.EmptyStackException] with root cause
java.util.EmptyStackException
        at java.util.Stack.peek(Stack.java:102)
        at java.util.Stack.pop(Stack.java:84)
        at org.apache.cocoon.callstack.CallStack.leave(CallStack.java:54)
        at org.apache.cocoon.servletservice.CallStackHelper.leaveServlet(CallStackHelper.java:85)
        at org.apache.cocoon.servletservice.ServletServiceContext$PathDispatcher.forward(ServletServiceContext.java:484)
        at org.apache.cocoon.servletservice.ServletServiceContext$PathDispatcher.forward(ServletServiceContext.java:443)
        at org.apache.cocoon.servletservice.spring.ServletFactoryBean$ServiceInterceptor.invoke(ServletFactoryBean.java:264)
        at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:172)
        at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:202)
        at com.sun.proxy.$Proxy90.service(Unknown Source)
        at org.dspace.springmvc.CocoonView.render(CocoonView.java:113)
        at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1180)
        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:950)
        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:852)
        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:882)
        at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:778)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:624)
        at javax.servlet.http.HttpServlet.service(HttpServlet.java:731)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.dspace.rdf.negotiation.NegotiationFilter.doFilter(NegotiationFilter.java:59)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.dspace.utils.servlet.DSpaceWebappServletFilter.doFilter(DSpaceWebappServletFilter.java:78)
        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)
        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)
        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:219)
        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)
        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:494)
        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)
        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:104)
        at org.apache.catalina.valves.CrawlerSessionManagerValve.invoke(CrawlerSessionManagerValve.java:234)
        at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:1025)
        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)
        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)
        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1137)
        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)
        at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:317)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
        at java.lang.Thread.run(Thread.java:748)
```

- For now I will just restart Tomcat...

## 2019-03-17

- Last week Felix from Earlham said that they finished testing on DSpace Test so I made backups of some things there and re-deployed the system on Ubuntu 18.04
  - During re-deployment I hit a few issues with the [Ansible playbooks](https://github.com/ilri/rmg-ansible-public) and made some minor improvements
  - There seems to be an [issue with nodejs's dependencies now](https://bugs.launchpad.net/ubuntu/+source/nodejs/+bug/1794589), which causes npm to get uninstalled when installing the certbot dependencies (due to a conflict in libssl dependencies)
  - I re-worked the playbooks to use Node.js from the upstream official repository for now

<!-- vim: set sw=2 ts=2: -->
