<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes on CGSpace Notes</title>
    <link>http://localhost:1313/cgspace-notes/categories/notes/</link>
    <description>Recent content in Notes on CGSpace Notes</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Jul 2025 09:26:00 -0700</lastBuildDate>
    <atom:link href="http://localhost:1313/cgspace-notes/categories/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>July, 2025</title>
      <link>http://localhost:1313/cgspace-notes/2025-07/</link>
      <pubDate>Thu, 24 Jul 2025 09:26:00 -0700</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2025-07/</guid>
      <description>&lt;h2 id=&#34;2025-07-24&#34;&gt;2025-07-24&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A few days ago I deployed nginx caching for the DSpace Angular frontend&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It works on collection, community, and item pages&lt;/li&gt;&#xA;&lt;li&gt;I modified the nginx proxy cache key to: &lt;code&gt;$request_uri$mapped_language$mapped_encoding&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2025</title>
      <link>http://localhost:1313/cgspace-notes/2025-04/</link>
      <pubDate>Sat, 05 Apr 2025 20:26:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2025-04/</guid>
      <description>&lt;h2 id=&#34;2025-04-05&#34;&gt;2025-04-05&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I noticed a bunch of IPs using a weird user agent&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>March, 2025</title>
      <link>http://localhost:1313/cgspace-notes/2025-03/</link>
      <pubDate>Mon, 17 Mar 2025 15:48:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2025-03/</guid>
      <description>&lt;h2 id=&#34;2025-03-17&#34;&gt;2025-03-17&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;We noticed that some PDFs do not have thumbnails despite having been uploaded months ago&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>February, 2025</title>
      <link>http://localhost:1313/cgspace-notes/2025-02/</link>
      <pubDate>Fri, 21 Feb 2025 11:09:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2025-02/</guid>
      <description>&lt;h2 id=&#34;2025-02-21&#34;&gt;2025-02-21&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Battling with high load on CGSpace from bots a few times the past few weeks&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I think I need to re-work the bot filtering some how&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>January, 2025</title>
      <link>http://localhost:1313/cgspace-notes/2025-01/</link>
      <pubDate>Fri, 03 Jan 2025 11:09:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2025-01/</guid>
      <description>&lt;h2 id=&#34;2025-01-03&#34;&gt;2025-01-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Trying to get search results for a large boolean query given to me by some researchers&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When searching via the Angular frontend I see an error in the Tomcat logs:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>December, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-12/</link>
      <pubDate>Wed, 04 Dec 2024 10:19:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-12/</guid>
      <description>&lt;h2 id=&#34;2024-12-04&#34;&gt;2024-12-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;We need to get view and download statistics for the last year from CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The only way to get that is using Solr&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>November, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-11/</link>
      <pubDate>Mon, 11 Nov 2024 09:47:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-11/</guid>
      <description>&lt;h2 id=&#34;2024-11-11&#34;&gt;2024-11-11&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Some IP in India is making tons of requests this morning with a normal user agent:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/api-access.log | sort | uniq -c | sort -h | tail -n &lt;span style=&#34;color:#ae81ff&#34;&gt;40&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;...&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;513743 49.207.196.249&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>October, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-10/</link>
      <pubDate>Thu, 03 Oct 2024 11:01:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-10/</guid>
      <description>&lt;h2 id=&#34;2024-10-03&#34;&gt;2024-10-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I had an idea to get abstracts from OpenAlex&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For &lt;a href=&#34;https://docs.openalex.org/api-entities/works/work-object#abstract_inverted_index&#34;&gt;copyright reasons they don&amp;rsquo;t include plain abstracts&lt;/a&gt;, but the &lt;a href=&#34;https://github.com/J535D165/pyalex&#34;&gt;pyalex&lt;/a&gt; library can convert them on the fly&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>September, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-09/</link>
      <pubDate>Sun, 01 Sep 2024 21:16:00 -0700</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-09/</guid>
      <description>&lt;h2 id=&#34;2024-09-01&#34;&gt;2024-09-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Upgrade CGSpace to DSpace 7.6.2&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>August, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-08/</link>
      <pubDate>Thu, 08 Aug 2024 23:07:00 -0700</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-08/</guid>
      <description>&lt;h2 id=&#34;2024-08-08&#34;&gt;2024-08-08&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;While working on the CGIAR Climate Change Synthesis I learned some new tricks with OpenRefine&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>July, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-07/</link>
      <pubDate>Mon, 01 Jul 2024 09:37:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-07/</guid>
      <description>&lt;h2 id=&#34;2024-07-01&#34;&gt;2024-07-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A bit of work to clean up duplicate DOIs on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A handful of book chapters, working papers, and journal articles using the wrong DOI&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I tried to delete all users who have been inactive since six years ago (July 1, 2018):&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>June, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-06/</link>
      <pubDate>Mon, 03 Jun 2024 14:14:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-06/</guid>
      <description>&lt;h2 id=&#34;2024-06-03&#34;&gt;2024-06-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Working on IFPRI datasets&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I noticed the licenses were missing from Nilam&amp;rsquo;s original file so I found a way to check &lt;a href=&#34;https://guides.dataverse.org/en/latest/api/native-api.html#export-metadata-of-a-dataset-in-various-formats&#34;&gt;Dataverse&amp;rsquo;s API for a persistent identifier&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;We have both Handles and DOIs for these datasets, both from Harvard&amp;rsquo;s Dataverse&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>May, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-05/</link>
      <pubDate>Wed, 01 May 2024 10:39:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-05/</guid>
      <description>&lt;h2 id=&#34;2024-05-01&#34;&gt;2024-05-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I dumped all the CGSpace DOIs and resolved them with my &lt;code&gt;crossref_doi_lookup.py&lt;/code&gt; script&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Then I did some work to add missing abstracts (about 900!), volumes, issues, licenses, publishers, and types, etc&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-04/</link>
      <pubDate>Thu, 04 Apr 2024 10:23:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-04/</guid>
      <description>&lt;h2 id=&#34;2024-04-04&#34;&gt;2024-04-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Work on CGSpace duplicate DOIs more&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>March, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-03/</link>
      <pubDate>Fri, 01 Mar 2024 09:55:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-03/</guid>
      <description>&lt;h2 id=&#34;2024-03-01&#34;&gt;2024-03-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Last week Bizu reported an issue with the &amp;ldquo;browse by issue date&amp;rdquo; drop down&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I verified it, and suspect it could be due to missing issue dates&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;It might be this issue: &lt;a href=&#34;https://github.com/DSpace/dspace-angular/issues/2808&#34;&gt;https://github.com/DSpace/dspace-angular/issues/2808&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>February, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-02/</link>
      <pubDate>Mon, 05 Feb 2024 11:10:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-02/</guid>
      <description>&lt;h2 id=&#34;2024-02-05&#34;&gt;2024-02-05&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Delete duplicate metadata as described in my DSpace issue from last year: &lt;a href=&#34;https://github.com/DSpace/DSpace/issues/8253&#34;&gt;https://github.com/DSpace/DSpace/issues/8253&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Lower case all the AGROVOC subjects on CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>January, 2024</title>
      <link>http://localhost:1313/cgspace-notes/2024-01/</link>
      <pubDate>Tue, 02 Jan 2024 10:08:00 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2024-01/</guid>
      <description>&lt;h2 id=&#34;2024-01-02&#34;&gt;2024-01-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Work on preparation of new server for DSpace 7 migration&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I&amp;rsquo;m not quite sure what we need to do for the Handle server&lt;/li&gt;&#xA;&lt;li&gt;For now I just ran the &lt;code&gt;dspace make-handle-config&lt;/code&gt; script and diffed it with the one from DSpace 6&lt;/li&gt;&#xA;&lt;li&gt;I sent the bundle to the Handle admins to make sure it&amp;rsquo;s OK before we do the migration&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Continue testing and debugging the cgspace-java-helpers on DSpace 7&lt;/li&gt;&#xA;&lt;li&gt;Work on IFPRI ISNAR archive cleanup&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>December, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-12/</link>
      <pubDate>Fri, 01 Dec 2023 08:48:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-12/</guid>
      <description>&lt;h2 id=&#34;2023-12-01&#34;&gt;2023-12-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There is still high load on CGSpace and I don&amp;rsquo;t know why&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I don&amp;rsquo;t see a high number of sessions compared to previous days in the last few weeks&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; file in dspace.log.2023-11-&lt;span style=&#34;color:#f92672&#34;&gt;[&lt;/span&gt;23&lt;span style=&#34;color:#f92672&#34;&gt;]&lt;/span&gt;*; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; echo &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$file&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;; grep -a -oE &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;session_id=[A-Z0-9]{32}&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt;$file&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;&lt;/span&gt; | sort | uniq | wc -l; &lt;span style=&#34;color:#66d9ef&#34;&gt;done&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-20&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22865&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-21&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;20296&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-22&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;19688&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-23&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17906&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-24&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;18453&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-25&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17513&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-26&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;19037&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-27&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;21103&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-28&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;23023&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-29&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;23545&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace.log.2023-11-30&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;21298&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Even the number of unique IPs is not very high compared to the last week or so:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;access,library-access,oai,rest&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;.log.1 | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17023&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;access,library-access,oai,rest&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;.log.2.gz | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17294&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;access,library-access,oai,rest&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;.log.3.gz | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22057&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;access,library-access,oai,rest&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;.log.4.gz | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;32956&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;access,library-access,oai,rest&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;.log.5.gz | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;11415&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;access,library-access,oai,rest&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;.log.6.gz | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;15444&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /var/log/nginx/&lt;span style=&#34;color:#f92672&#34;&gt;{&lt;/span&gt;access,library-access,oai,rest&lt;span style=&#34;color:#f92672&#34;&gt;}&lt;/span&gt;.log.7.gz | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;12648&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;It doesn&amp;rsquo;t make any sense so I think I&amp;rsquo;m going to restart the server&amp;hellip;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;After restarting the server the load went down to normal levels&amp;hellip; who knows&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I started trying to see how I&amp;rsquo;m going to generate the fake statistics for the Alliance bitstream that was replaced&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I exported all the statistics for the owningItem now:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ chrt -b &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; ./run.sh -s http://localhost:8081/solr/statistics -a export -o /tmp/stats-export.json -f &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;owningItem:b5862bfa-9799-4167-b1cf-76f0f4ea1e18&amp;#39;&lt;/span&gt; -k uid&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Importing them into DSpace Test didn&amp;rsquo;t show the statistics in the Atmire module, but I see them in Solr&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-02&#34;&gt;2023-12-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check for missing Initiative collection mappings&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-04&#34;&gt;2023-12-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Send a message to Altmetric support because the item IWMI highlighted last month still doesn&amp;rsquo;t show the attention score for the Handle after I tweeted it several times weeks ago&lt;/li&gt;&#xA;&lt;li&gt;Spent some time writing a Python script to fix the literal MaxMind City JSON objects in our Solr statistics&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There are about 1.6 million of these, so I exported them using solr-import-export-json with the query &lt;code&gt;city:com*&lt;/code&gt; but ended up finding many that have missing bundles, container bitstreams, etc:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;city:com* AND -bundleName:[* TO *] AND -containerBitstream:[* TO *] AND -file_id:[* TO *] AND -owningItem:[* TO *] AND -version_id:[* TO *]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;(Note the negation to find fields that are missing)&lt;/li&gt;&#xA;&lt;li&gt;I don&amp;rsquo;t know what I want to do with these yet&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-05&#34;&gt;2023-12-05&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I finished the &lt;code&gt;fix_maxmind_stats.py&lt;/code&gt; script and fixed 1.6 million records and imported them on CGSpace after testing on DSpace 7 Test&lt;/li&gt;&#xA;&lt;li&gt;Altmetric said there was a glitch regarding the Handle and DOI linking and they successfully re-scraped the item page and linked them&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They sent me a list of current production IPs and I notice that some of them are in our nginx bot network list:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; network in &lt;span style=&#34;color:#66d9ef&#34;&gt;$(&lt;/span&gt;csvcut -c network /tmp/ips.csv | sed 1d | sort -u&lt;span style=&#34;color:#66d9ef&#34;&gt;)&lt;/span&gt;; &lt;span style=&#34;color:#66d9ef&#34;&gt;do&lt;/span&gt; grepcidr $network ~/src/git/rmg-ansible-public/roles/dspace/files/nginx/bot-networks.conf; &lt;span style=&#34;color:#66d9ef&#34;&gt;done&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;108.128.0.0/13 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;46.137.0.0/16 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;52.208.0.0/13 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;52.48.0.0/13 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;54.194.0.0/15 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;54.216.0.0/14 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;54.220.0.0/15 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;54.228.0.0/15 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;63.32.242.35/32     &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;63.32.0.0/14 &amp;#39;bot&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;99.80.0.0/15 &amp;#39;bot&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I will remove those for now so that Altmetric doesn&amp;rsquo;t have any unexpected issues harvesting&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-08&#34;&gt;2023-12-08&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Finalized the script to generate Solr statistics for Alliance research Mirjam&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The script is &lt;code&gt;ilri/generate_solr_statistics.py&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;I generated ~3,200 statistics based on her records of the download statistics of &lt;a href=&#34;https://hdl.handle.net/10568/131997&#34;&gt;that item&lt;/a&gt; and imported them on CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Did some work on the DSpace 7 submission form&lt;/li&gt;&#xA;&lt;li&gt;Peter asked for lists of affiliations, investors, and publishers to do some cleanups&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I generated a list from a CSV export instead of doing it based on a SQL dump&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cg.contributor.affiliation[en_US]&amp;#39;&lt;/span&gt; /tmp/initiatives.csv       &lt;span style=&#34;color:#ae81ff&#34;&gt;\&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  | sed -e 1d -e &amp;#39;s/^&amp;#34;//&amp;#39; -e &amp;#39;s/&amp;#34;$//&amp;#39; -e &amp;#39;s/||/\n/g&amp;#39; -e &amp;#39;/^$/d&amp;#39;            \&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  | sort | uniq -c | sort -hr                                              \&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  | awk &amp;#39;BEGIN { FS = &amp;#34;^[[:space:]]+[[:digit:]]+[[:space:]]+&amp;#34; } {print $2}&amp;#39;\&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  | sed -e &amp;#39;1i cg.contributor.affiliation&amp;#39; -e &amp;#39;s/^\(.*\)$/&amp;#34;\1&amp;#34;/&amp;#39;           \&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &amp;gt; /tmp/2023-12-08-initiatives-affiliations.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Export a list of authors as well:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;localhost/dspace7= ☘ \COPY (SELECT DISTINCT text_value AS &amp;#34;dc.contributor.author&amp;#34;, count(*) FROM metadatavalue WHERE dspace_object_id in (SELECT dspace_object_id FROM item) AND metadata_field_id = 3 GROUP BY &amp;#34;dc.contributor.author&amp;#34; ORDER BY count DESC) to /tmp/2023-12-08-authors.csv WITH CSV HEADER;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;COPY 102435&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2023-12-11&#34;&gt;2023-12-11&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Work on OpenRXV dependencies and podman a bit&lt;/li&gt;&#xA;&lt;li&gt;Peter noticed that the statistics for this month are very very low on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I don&amp;rsquo;t know what is going on, perhaps it is related to me adjusting the nginx config last week?&lt;/li&gt;&#xA;&lt;li&gt;Ah, it&amp;rsquo;s probably because of the spider patterns I updated on 2023-11&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-16&#34;&gt;2023-12-16&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check for missing Initiative collection mappings&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-17&#34;&gt;2023-12-17&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Pull latest master branch for OpenRXV and deploy on the server&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I threw away some changes in the tree regarding the Angular base ref, and it broke AReS&lt;/li&gt;&#xA;&lt;li&gt;So note to self: we need to set the base ref in &lt;code&gt;frontend/Dockerfile&lt;/code&gt; before building!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Now Salem fixed the country map&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-18&#34;&gt;2023-12-18&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Work a bit on the IFPRI-ISNAR archive from Leigh&lt;/li&gt;&#xA;&lt;li&gt;More work on the DSpace 7 home page&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-19&#34;&gt;2023-12-19&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;More work on the DSpace 7 home page&lt;/li&gt;&#xA;&lt;li&gt;The Alliance TIP team is testing deposits to the DSpace 7 REST API and getting an HTTP 500 error&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In the DSpace logs I see this after they log in, create the item, and update the metadata:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2023-12-19 17:49:28,022 ERROR unknown unknown org.dspace.rest.Resource @ Something get wrong. Aborting context in finally statement.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;I found some messages on the dspace-tech mailing list suggesting this might be an old bug: &lt;a href=&#34;https://groups.google.com/g/dspace-tech/c/My1GUFYFGoU/m/tS7-WAJPAwAJ&#34;&gt;https://groups.google.com/g/dspace-tech/c/My1GUFYFGoU/m/tS7-WAJPAwAJ&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I restarted Tomcat and told the Alliance TIP team to try again&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-20&#34;&gt;2023-12-20&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The Alliance guys said that submitting via REST works now&amp;hellip; sigh, so that&amp;rsquo;s just some old DSpace 5/6 REST API bug&lt;/li&gt;&#xA;&lt;li&gt;I lowercased all our AGROVOC keywords in &lt;code&gt;dcterms.subject&lt;/code&gt; in SQL:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace=# BEGIN;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;BEGIN&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace=*# UPDATE metadatavalue SET text_value=LOWER(text_value) WHERE dspace_object_id IN (SELECT uuid FROM item) AND metadata_field_id=187 AND text_value ~ &amp;#39;[[:upper:]]&amp;#39;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;UPDATE 462&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dspace=*# COMMIT;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;COMMIT&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2023-12-25&#34;&gt;2023-12-25&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Looking into &lt;a href=&#34;https://solr.apache.org/guide/8_11/making-and-restoring-backups.html&#34;&gt;Solr backups&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Since we are not running in Solr Cloud mode we need to use the replication endpoint for Solr standalone&lt;/li&gt;&#xA;&lt;li&gt;This works:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ curl &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://localhost:8983/solr/statistics/replication?command=backup&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &amp;#34;responseHeader&amp;#34;:{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;#34;status&amp;#34;:0,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;#34;QTime&amp;#34;:26},&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &amp;#34;status&amp;#34;:&amp;#34;OK&amp;#34;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Then I saw the size of the snapshot reach the size of the index&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# du -sh /var/solr/data/configsets/statistics/data/*&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22G     /var/solr/data/configsets/statistics/data/index&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;16G     /var/solr/data/configsets/statistics/data/snapshot.20231225074111671&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;4.0K    /var/solr/data/configsets/statistics/data/snapshot_metadata&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# du -sh /var/solr/data/configsets/statistics/data/*&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22G     /var/solr/data/configsets/statistics/data/index&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;20G     /var/solr/data/configsets/statistics/data/snapshot.20231225074111671&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;4.0K    /var/solr/data/configsets/statistics/data/snapshot_metadata&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# du -sh /var/solr/data/configsets/statistics/data/*&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22G     /var/solr/data/configsets/statistics/data/index&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;21G     /var/solr/data/configsets/statistics/data/snapshot.20231225074111671&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;4.0K    /var/solr/data/configsets/statistics/data/snapshot_metadata&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# du -sh /var/solr/data/configsets/statistics/data/*&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22G     /var/solr/data/configsets/statistics/data/index&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22G     /var/solr/data/configsets/statistics/data/snapshot.20231225074111671&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;4.0K    /var/solr/data/configsets/statistics/data/snapshot_metadata&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Then I deleted the core and restored from the snapshot backup:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ curl http://localhost:8983/solr/statistics/update -H &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Content-type: text/xml&amp;#34;&lt;/span&gt; --data-binary &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;delete&amp;gt;&amp;lt;query&amp;gt;*:*&amp;lt;/query&amp;gt;&amp;lt;/delete&amp;gt;&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ curl http://localhost:8983/solr/statistics/update -H &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Content-type: text/xml&amp;#34;&lt;/span&gt; --data-binary &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;&amp;lt;commit /&amp;gt;&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ curl &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://localhost:8983/solr/statistics/replication?command=restore&amp;amp;name=statistics&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Interestingly the import worked fine, but created a new data index:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# du -sh /var/solr/data/configsets/statistics/data/*&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;4.0K    /var/solr/data/configsets/statistics/data/index.properties&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22G     /var/solr/data/configsets/statistics/data/restore.20231225154626463&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;4.0K    /var/solr/data/configsets/statistics/data/snapshot_metadata&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;22G     /var/solr/data/configsets/statistics/data/snapshot.statistics&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Not sure the implications of that—Solr uses the data just fine&lt;/li&gt;&#xA;&lt;li&gt;I can surely use this for atomic Solr backups&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-27&#34;&gt;2023-12-27&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Delete duplicate metadata as described in my DSpace issue from last year: &lt;a href=&#34;https://github.com/DSpace/DSpace/issues/8253&#34;&gt;https://github.com/DSpace/DSpace/issues/8253&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Do some other metadata cleanups on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I also looked up our DOIs on Crossref to get some missing abstracts and correct licenses and dates&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Some minor work on the CGSpace DSpace 7 theme to fix the navbar on mobile&lt;/li&gt;&#xA;&lt;li&gt;Some work on the IFPRI ISNAR archive&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-28&#34;&gt;2023-12-28&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I started porting the &lt;a href=&#34;https://github.com/ilri/cgspace-java-helpers&#34;&gt;cgspace-java-helpers&lt;/a&gt; to DSpace 7&lt;/li&gt;&#xA;&lt;li&gt;Some work on the IFPRI ISNAR archive&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I ended up going through most of the PDFs to get better dates and abstracts&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-12-29&#34;&gt;2023-12-29&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I created a new Hetzner server to replace the current DSpace 6 CGSpace next week when we migrate to DSpace 7&lt;/li&gt;&#xA;&lt;li&gt;Interesting, I haven&amp;rsquo;t checked for content pointing to legacy domains in several years (!)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;inurl:mahider.cgiar.org&lt;/code&gt;: 0 results on Google!&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;inurl:mahider.ilri.org&lt;/code&gt;: 2,100 results on Google&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;inurl:mahider.ilri.org inurl:https&lt;/code&gt;: 2 results on Google (!)&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;inurl:dspace.ilri.org:&lt;/code&gt; 1,390 results on Google&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;inurl:dspace.ilri.org inurl:https&lt;/code&gt;: 0 results on Google (!)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;So it seems I can do away with the HTTPS virtual hosts finally&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Well my current certificates expired on 2021-02-13 and nobody noticed&amp;hellip; so&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>November, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-11/</link>
      <pubDate>Thu, 02 Nov 2023 12:59:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-11/</guid>
      <description>&lt;h2 id=&#34;2023-11-01&#34;&gt;2023-11-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Work a bit on the ETL pipeline for the CGIAR Climate Change Synthesis&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I improved the filtering and wrote some Python using pandas to merge my sources more reliably&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-11-02&#34;&gt;2023-11-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check missing Initiative collection mappings&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>October, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-10/</link>
      <pubDate>Mon, 02 Oct 2023 09:05:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-10/</guid>
      <description>&lt;h2 id=&#34;2023-10-02&#34;&gt;2023-10-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check DOIs against Crossref&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I found that &lt;a href=&#34;https://www.crossref.org/documentation/retrieve-metadata/rest-api/rest-api-metadata-license-information/&#34;&gt;Crossref&amp;rsquo;s metadata is in the public domain under the CC0 license&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;One interesting thing is the abstracts, which are copyrighted by the copyright owner, meaning Crossref cannot waive the copyright under the terms of the CC0 license, because it is not theirs to waive&lt;/li&gt;&#xA;&lt;li&gt;We can be on the safe side by using only abstracts for items that are licensed under Creative Commons&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>September, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-09/</link>
      <pubDate>Sat, 02 Sep 2023 17:29:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-09/</guid>
      <description>&lt;h2 id=&#34;2023-09-02&#34;&gt;2023-09-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check for missing Initiative collection mappings&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>August, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-08/</link>
      <pubDate>Thu, 03 Aug 2023 11:18:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-08/</guid>
      <description>&lt;h2 id=&#34;2023-08-03&#34;&gt;2023-08-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I finally got around to working on Peter&amp;rsquo;s cleanups for affiliations, authors, and donors from last week&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I did some minor cleanups myself and applied them to CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Start working on some batch uploads for IFPRI&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>July, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-07/</link>
      <pubDate>Sat, 01 Jul 2023 17:14:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-07/</guid>
      <description>&lt;h2 id=&#34;2023-07-01&#34;&gt;2023-07-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check for missing Initiative collection mappings&lt;/li&gt;&#xA;&lt;li&gt;Start harvesting on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-02&#34;&gt;2023-07-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Minor edits to the &lt;code&gt;crossref_doi_lookup.py&lt;/code&gt; script while running some checks from 22,000 CGSpace DOIs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-03&#34;&gt;2023-07-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I analyzed the licenses declared by Crossref and found with high confidence that ~400 of ours were incorrect&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I took the more accurate ones from Crossref and updated the items on CGSpace&lt;/li&gt;&#xA;&lt;li&gt;I took a few hundred ISBNs as well for where we were missing them&lt;/li&gt;&#xA;&lt;li&gt;I also tagged ~4,700 items with missing licenses as &amp;ldquo;Copyrighted; all rights reserved&amp;rdquo; based on their Crossref license status being TDM, mostly from Elsevier, Wiley, and Springer&lt;/li&gt;&#xA;&lt;li&gt;Checking a dozen or so manually, I confirmed that if Crossref only has a TDM license then it&amp;rsquo;s usually copyrighted (could still be open access, but we can&amp;rsquo;t tell via Crossref)&lt;/li&gt;&#xA;&lt;li&gt;I would be curious to write a script to check the Unpaywall API for open access status&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;In the past I found that their &lt;em&gt;license&lt;/em&gt; status was not very accurate, but the open access status might be more reliable&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;More minor work on the DSpace 7 item views&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I learned some new Angular template syntax&lt;/li&gt;&#xA;&lt;li&gt;I created a custom component to show Creative Commons licenses on the simple item page&lt;/li&gt;&#xA;&lt;li&gt;I also decided that I don&amp;rsquo;t like the Impact Area icons as a component because they don&amp;rsquo;t have any visual meaning&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-04&#34;&gt;2023-07-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Focus group meeting with CGSpace partners about DSpace 7&lt;/li&gt;&#xA;&lt;li&gt;I added a themed file selection component to the CGSpace theme&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It displays the bistream description instead of the file name, just like we did in DSpace 6 XMLUI&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I added a custom component to show share icons&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-05&#34;&gt;2023-07-05&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I spent some time trying to update OpenRXV from Angular 9 to 10 to 11 to 12 to 13&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Most things work but there are some minor bugs it seems&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Mishell from CIP emailed me to say she was having problems approving an item on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Looking at PostgreSQL I saw there were a dozen or so locks that were several hours and even over one day old so I killed those processes and told her to try again&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-06&#34;&gt;2023-07-06&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Types meeting&lt;/li&gt;&#xA;&lt;li&gt;I wrote a Python script to check Unpaywall for some information about DOIs&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-7&#34;&gt;2023-07-7&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Continue exploring Unpaywall data for some of our DOIs&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In the past I&amp;rsquo;ve found their &lt;em&gt;licensing&lt;/em&gt; information to not be very reliable (preferring Crossref), but I think their &lt;em&gt;open access status&lt;/em&gt; is more reliable, especially when the provider is listed as being the publisher&lt;/li&gt;&#xA;&lt;li&gt;Even so, sometimes the version can be &amp;ldquo;acceptedVersion&amp;rdquo;, which is presumably the author&amp;rsquo;s version, as opposed to the &amp;ldquo;publishedVersion&amp;rdquo;, which means it&amp;rsquo;s available as open access on the publisher&amp;rsquo;s website&lt;/li&gt;&#xA;&lt;li&gt;I did some quality assurance and found ~100 that were marked as Limited Access, but should have been Open Access, and fixed a handful of licenses&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Delete duplicate metadata as described in my DSpace issue from last year: &lt;a href=&#34;https://github.com/DSpace/DSpace/issues/8253&#34;&gt;https://github.com/DSpace/DSpace/issues/8253&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Start working on some statistics on AGROVOC usage for my presenation next week&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I used the following SQL query to dump values from all subject fields and lower case them:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;localhost/dspacetest= ☘ \COPY (SELECT DISTINCT(lower(text_value)) AS &amp;#34;subject&amp;#34; FROM metadatavalue WHERE dspace_object_id in (SELECT dspace_object_id FROM item) AND metadata_field_id IN (187, 120, 210, 122, 215, 127, 208, 124, 128, 123, 125, 135, 203, 236, 238, 119)) to /tmp/2023-07-07-cgspace-subjects.csv WITH CSV HEADER;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;COPY 26443&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Time: 2564.851 ms (00:02.565)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Then I extracted the subjects and looked them up against AGROVOC:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c subject /tmp/2023-07-07-cgspace-subjects.csv | sed &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;1d&amp;#39;&lt;/span&gt; &amp;gt; /tmp/2023-07-07-cgspace-subjects.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./ilri/agrovoc_lookup.py -i /tmp/2023-07-07-cgspace-subjects.txt -o /tmp/2023-07-07-cgspace-subjects-results.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I did some more tests with Angular 13 on OpenRXV and found out why the repository type dropdown wasn&amp;rsquo;t working&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It was because of a missing 1-line JSON file in the data directory, which is runtime data, not code&lt;/li&gt;&#xA;&lt;li&gt;I copied the data directory from the production serve and rebuild and the site is working well now&lt;/li&gt;&#xA;&lt;li&gt;I did a full harvest with plugins and it worked!&lt;/li&gt;&#xA;&lt;li&gt;So it seems Angular 13.4.0 will work, yay&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-08&#34;&gt;2023-07-08&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check for missing Initiative collection mappings&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;The AGROVOC lookup finished, so I checked the number of matches:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvgrep -c &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;match type&amp;#39;&lt;/span&gt; -r &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;^.+$&amp;#39;&lt;/span&gt; ~/Downloads/2023-07-07-cgspace-subjects-resolved.csv | sed 1d | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;12528&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;So that&amp;rsquo;s 12,528 out of 26,443 unique terms (47.3%)&lt;/li&gt;&#xA;&lt;li&gt;I did a LOT of work on the OpenRXV frontend build dependencies to bring more in line with Angular 13&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-10&#34;&gt;2023-07-10&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I did a lot more work on OpenRXV to test and update dependencies&lt;/li&gt;&#xA;&lt;li&gt;I deployed the latest version on the production server&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-12&#34;&gt;2023-07-12&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;CGSpace upgrade meeting with Americas and Africa group&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-13&#34;&gt;2023-07-13&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Michael Victor asked me to help Aditi extract some information from CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;She was interested in journal articles published between 2018 and 2023 with a range of subjects related to drought, flooding, resilience, etc&lt;/li&gt;&#xA;&lt;li&gt;I used an advanced query with some AGROVOC terms:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;dcterms.issued:[2018 TO 2023] AND dcterms.type:&amp;#34;Journal Article&amp;#34; AND (dcterms.subject:flooding OR dcterms.subject:flood OR dcterms.subject:&amp;#34;extreme weather events&amp;#34; OR dcterms.subject:drought OR dcterms.subject:&amp;#34;drought resistance&amp;#34; OR dcterms.subject:&amp;#34;drought tolerance&amp;#34; OR dcterms.subject:&amp;#34;soil salinity&amp;#34; OR dcterms.subject:&amp;#34;pests of plants&amp;#34; OR dcterms.subject:pests OR dcterms.subject:heat OR dcterms.subject:fertilizers OR dcterms.subject:&amp;#34;fertilizer technology&amp;#34; OR dcterms.subject:&amp;#34;rice fields&amp;#34; OR dcterms.subject:&amp;#34;landscape conservation&amp;#34; OR dcterms.subject:&amp;#34;landscape restoration&amp;#34; OR dcterms.subject:livestock)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Interestingly, some variations of this same exact query produce no search results, and I see this error in the DSpace log:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;org.dspace.discovery.SearchServiceException: org.apache.solr.search.SyntaxError: Cannot parse &amp;#39;dcterms.issued:[2018 TO 2023] AND dcterms.type:&amp;#34;Journal Article&amp;#34; AND (dcterms.subject:flooding OR dcterms.subject:flood OR dcterms.subject:&amp;#34;extreme weather events&amp;#34; OR dcterms.subject:drought OR dcterms.subject:&amp;#34;drought resistance&amp;#34; OR dcterms.subject:&amp;#34;drought tolerance&amp;#34; OR dcterms.subject:&amp;#34;soil salinity&amp;#34; OR dcterms.subject:&amp;#34;pests of plants&amp;#34; OR dcterms.subject:pests OR dcterms.subject:heat OR dcterms.subject:fertilizers OR dcterms.subject:&amp;#34;fertilizer technology&amp;#34; OR dcterms.subject:&amp;#34;rice fields&amp;#34; OR dcterms.subject:livestock OR dcterms.subject:&amp;#34;landscape conservation&amp;#34; OR dcterms.subject:&amp;#34;landscape restoration\&amp;#34;\)&amp;#39;: Lexical error at line 1, column 617.  Encountered: &amp;lt;EOF&amp;gt; after : &amp;#34;\&amp;#34;landscape restoration\\\&amp;#34;\\)&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;It seems to be when there is a quoted search term at the end of the parenthesized group&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For what it&amp;rsquo;s worth this same query worked fine on DSpace 7.6&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-15&#34;&gt;2023-07-15&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to fix missing Initiative collection mappings&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-17&#34;&gt;2023-07-17&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Rasika had sent me a list of new ORCID identifiers for new IWMI staff so I combined them with our existing list and ran &lt;code&gt;resolve_orcids.py&lt;/code&gt; to refresh the names in our database&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I updated the list, updated names in the database, and tagged new authors with missing identifiers in existing items&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-18&#34;&gt;2023-07-18&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Meeting with IWMI, IRRI, and IITA colleagues about CGSpace upgrade plans&lt;/li&gt;&#xA;&lt;li&gt;Maria from the Alliance mentioned having some submissions stuck on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I looked and found a number of locks stuck for many nineteen, eighteen, and more hours&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;I killed them and told her to try again&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ psql &amp;lt; locks-age.sql | less -S&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ psql &amp;lt; locks-age.sql | grep -E &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34; (19|18|17|16|12):&amp;#34;&lt;/span&gt; | awk -F&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $10}&amp;#39;&lt;/span&gt; | sort -u | xargs kill&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2023-07-19&#34;&gt;2023-07-19&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I had to kill a bunch more locked processes in PostgreSQL, I&amp;rsquo;m not sure what&amp;rsquo;s going on&lt;/li&gt;&#xA;&lt;li&gt;After some discussion about an advanced search bug with Tim on Slack, I filed &lt;a href=&#34;https://github.com/DSpace/DSpace/issues/8962&#34;&gt;an issue on GitHub&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-20&#34;&gt;2023-07-20&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I added a new metadata field for CGIAR Impact Platforms (&lt;code&gt;cg.subject.impactPlatform&lt;/code&gt;) to CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-22&#34;&gt;2023-07-22&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace tp fix missing Initiative collections&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-24&#34;&gt;2023-07-24&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Test Salem&amp;rsquo;s new JavaScript-based DSpace Statistics API and send him some feedback&lt;/li&gt;&#xA;&lt;li&gt;I noticed a few times that the Solr service on my DSpace 7 instance is getting OOM killed&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I had been using a 4g Solr heap, but maybe we don&amp;rsquo;t need that much&lt;/li&gt;&#xA;&lt;li&gt;Tomcat is also using 4.6GB, and then there&amp;rsquo;s PostgreSQL&amp;hellip; so perhaps it&amp;rsquo;s all a bit much on this system now&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-25&#34;&gt;2023-07-25&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start testing exporting DSpace 6 Solr cores to import on DSpace 7:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ chrt -b &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; dspace solr-export-statistics -i statistics&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I&amp;rsquo;m curious how long it takes and how much data there will be&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The size of the Solr data directory is currently 82GB&lt;/li&gt;&#xA;&lt;li&gt;The export took about 2.5 hours and created 6,000 individual CSVs, one for each day of Solr stats&lt;/li&gt;&#xA;&lt;li&gt;The size of the exported CSVs is about 88GB&lt;/li&gt;&#xA;&lt;li&gt;I will copy just a few years to import on the DSpace 7 test server&lt;/li&gt;&#xA;&lt;li&gt;So importing these is going to require removing the Atmire custom fields:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ dspace solr-import-statistics -i statistics&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Exception: Error from server at http://localhost:8983/solr/statistics: ERROR: [doc=1a92472e-e39d-4602-9b4d-da022df8f233] unknown field &amp;#39;containerCommunity&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/statistics: ERROR: [doc=1a92472e-e39d-4602-9b4d-da022df8f233] unknown field &amp;#39;containerCommunity&amp;#39;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:681)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:266)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:248)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.SolrClient.request(SolrClient.java:1290)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.dspace.util.SolrImportExport.importIndex(SolrImportExport.java:465)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.dspace.util.SolrImportExport.main(SolrImportExport.java:148)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.lang.reflect.Method.invoke(Method.java:568)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.dspace.app.launcher.ScriptLauncher.runOneCommand(ScriptLauncher.java:277)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.dspace.app.launcher.ScriptLauncher.handleScript(ScriptLauncher.java:133)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.dspace.app.launcher.ScriptLauncher.main(ScriptLauncher.java:98)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I will try using solr-import-export-json, which I&amp;rsquo;ve used in the past to skip Atmire custom fields in Solr:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ chrt -b &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; ./run.sh -s http://localhost:8081/solr/statistics -a export -o /tmp/statistics-2022.json -f &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;time:[2022-01-01T00\:00\:00Z TO 2022-12-31T23\:59\:59Z]&amp;#39;&lt;/span&gt; -k uid -S author_mtdt,author_mtdt_search,iso_mtdt_search,iso_mtdt,subject_mtdt,subject_mtdt_search,containerCollection,containerCommunity,containerItem,countryCode_ngram,countryCode_search,cua_version,dateYear,dateYearMonth,geoipcountrycode,geoIpCountryCode,ip_ngram,ip_search,isArchived,isInternal,isWithdrawn,containerBitstream,file_id,referrer_ngram,referrer_search,userAgent_ngram,userAgent_search,version_id,complete_query,complete_query_search,filterquery,ngram_query_search,ngram_simplequery_search,simple_query,simple_query_search,range,rangeDescription,rangeDescription_ngram,rangeDescription_search,range_ngram,range_search,actingGroupId,actorMemberGroupId,bitstreamCount,solr_update_time_stamp,bitstreamId,core_update_run_nb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Some users complained that CGSpace was slow and I found a handful of locks that were hours and days old&amp;hellip;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I killed those and told them to try again&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;After importing the Solr statistics into DSpace 7 I realized that my DSpace Statistics API will work fine&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I made some minor modifications to the Ansible infrastructure scripts to make sure it is enabled and then activated it on DSpace 7 Test&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-26&#34;&gt;2023-07-26&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Debugging lock issues on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I see the blocking PIDs for some long-held locks are &amp;ldquo;idle in transaction&amp;rdquo;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ps auxw | grep -E &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;(1864132|1659487)&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;postgres 1659487  0.0  0.5 3269900 197120 ?      Ss   Jul25   0:03 postgres: 14/main: cgspace cgspace 127.0.0.1(61648) idle in transaction&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;postgres 1864132  0.1  0.7 3275704 254528 ?      Ss   07:27   0:08 postgres: 14/main: cgspace cgspace 127.0.0.1(36998) idle in transaction&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;postgres 1880388  0.0  0.0   9208  2432 pts/3    S+   08:48   0:00 grep -E (1864132|1659487)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I used some other scripts and found that those processes were executing the following statement:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;select nextval (&amp;#39;public.tasklistitem_seq&amp;#39;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I don&amp;rsquo;t know why these can get blocked for hours without resolution, but for now I just killed them&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For what it&amp;rsquo;s worth &lt;a href=&#34;https://github.com/DSpace/DSpace/commit/16ae96b4c3d833c2a4acd1f05985d424c3a52bd7&#34;&gt;these sequences were removed in DSpace 7.0&lt;/a&gt; along with the &amp;ldquo;traditional&amp;rdquo; item workflow—maybe that means we won&amp;rsquo;t have such contention issues in DSpace 7!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I wrote a slightly longer regex to match locks that have been stuck for more than 1 hour based on the output of the &lt;code&gt;locks-age.sql&lt;/code&gt; script and killed them:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ psql &amp;lt; locks-age.sql | awk -F&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/ [[:digit:]][1-9]:[[:digit:]]{2}:[[:digit:]]{2}\./ {print $10}&amp;#39;&lt;/span&gt; | sort -u | xargs kill&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I filed &lt;a href=&#34;https://github.com/DSpace/dspace-angular/issues/2400&#34;&gt;an issue for missing Altmetric badges on DSpace 7 Angular&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-27&#34;&gt;2023-07-27&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to check countries, regions, types, and Initiatives&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There were a few minor issues in countries and regions, and I noticed 186 items without types!&lt;/li&gt;&#xA;&lt;li&gt;Then I ran the file through csv-metadata-quality to make sure items with countries have appropriate regions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Brief discussion about OpenRXV bugs and fixes with Moayad&lt;/li&gt;&#xA;&lt;li&gt;I was toying with the idea of using an expanded whitespace check/fix based on &lt;a href=&#34;https://eslint.org/docs/latest/rules/no-irregular-whitespace&#34;&gt;ESLint&amp;rsquo;s no-irregular-whitespace&lt;/a&gt; rule in csv-metadata-quality&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I found 176 items in CGSpace with such whitespace in their titles alone&lt;/li&gt;&#xA;&lt;li&gt;I compared the results of removing these characters and replacing them with a space&lt;/li&gt;&#xA;&lt;li&gt;In &lt;em&gt;most&lt;/em&gt; cases removing it is the correct thing to do, for example &amp;ldquo;Pesticides : une arme à double tranchant&amp;rdquo; → &amp;ldquo;Pesticides: une arme à double tranchant&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;But in some items it is tricky, for example &amp;ldquo;L&amp;rsquo;environnement juridique est-il propice à la gestion&amp;rdquo; → &amp;ldquo;L&amp;rsquo;environnement juridique est-il propice àla gestion&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;I guess it would really need some good heuristics or a human to verify&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I upgraded OpenRXV to Angular v14&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-28&#34;&gt;2023-07-28&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;After a bit more testing I merged the &lt;a href=&#34;https://github.com/ilri/OpenRXV/pull/184&#34;&gt;Angular v14 changes to OpenRXV master&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;I am getting an error trying to import the 2020 Solr statistics from CGSpace to DSpace 7:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Exception in thread &amp;#34;main&amp;#34; org.apache.solr.client.solrj.impl.BaseHttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/statistics: ERROR: [doc=0008a7c1-e552-4a4e-93e4-4d23bf39964b] Error adding field &amp;#39;workflowItemId&amp;#39;=&amp;#39;0812be47-1bfe-45e2-9208-5bf10ee46f81&amp;#39; msg=For input string: &amp;#34;0812be47-1bfe-45e2-9208-5bf10ee46f81&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:745)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:259)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:240)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.SolrRequest.process(SolrRequest.java:234)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:102)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:69)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at org.apache.solr.client.solrj.SolrClient.add(SolrClient.java:82)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at it.damore.solr.importexport.App.insertBatch(App.java:295)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at it.damore.solr.importexport.App.lambda$writeAllDocuments$10(App.java:276)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at it.damore.solr.importexport.BatchCollector.lambda$accumulator$0(BatchCollector.java:71)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1845)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:921)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:682)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at it.damore.solr.importexport.App.writeAllDocuments(App.java:252)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        at it.damore.solr.importexport.App.main(App.java:150)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Ahhhh, in DSpace 6 this field was a string in the Solr statistics schema, but in DSpace 7 it is an integer&amp;hellip;?&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Oh, it seems to be an Atmire change in our DSpace 6&amp;hellip; hmmm, so we need to ignore the &lt;code&gt;workflowItemId&lt;/code&gt; field when exporting&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Upstream: &lt;a href=&#34;https://github.com/DSpace/DSpace/blob/dspace-6_x/dspace/solr/statistics/conf/schema.xml#L328&#34;&gt;https://github.com/DSpace/DSpace/blob/dspace-6_x/dspace/solr/statistics/conf/schema.xml#L328&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ILRI: &lt;a href=&#34;https://github.com/ilri/DSpace/blob/6_x-prod/dspace/solr/statistics/conf/schema.xml#L344&#34;&gt;https://github.com/ilri/DSpace/blob/6_x-prod/dspace/solr/statistics/conf/schema.xml#L344&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I am wondering if we can skip all these workflow fields since I don&amp;rsquo;t think we are using any aspects of statistics related to workflows&lt;/li&gt;&#xA;&lt;li&gt;I diffed our Solr statistics schema with the one from vanilla DSpace 6 and got a list of all the fields that were different:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;isInternal,workflowItemId,containerCommunity,containerCollection,containerItem,containerBitstream,dateYear,dateYearMonth,filterquery,complete_query,simple_query,complete_query_search,simple_query_search,ngram_query_search,ngram_simplequery_search,text,storage_statistics_type,storage_size,storage_nb_of_bitstreams,name,first_name,last_name,p_communities_id,p_communities_name,p_communities_map,p_group_id,p_group_name,p_group_map,group_id,group_name,group_map,parent_count,bitstreamId,bitstreamCount,actingGroupId,actorMemberGroupId,actingGroupParentId,rangeDescription,range,version_id,file_id,cua_version,core_update_run_nb,orphaned&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;I will combine it with the other fields I was skipping above and try the export again:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ chrt -b &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt; ./run.sh -s http://localhost:8081/solr/statistics -a export -o /tmp/statistics-2020.json -f &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;time:[2020-01-01T00\:00\:00Z TO 2020-12-31T23\:59\:59Z]&amp;#39;&lt;/span&gt; -k uid -S actingGroupId,actingGroupParentId,actorMemberGroupId,author_mtdt,author_mtdt_search,bitstreamCount,bitstreamId,complete_query,complete_query_search,containerBitstream,containerCollection,containerCommunity,containerItem,core_update_run_nb,countryCode_ngram,countryCode_search,cua_version,dateYear,dateYearMonth,file_id,filterquery,first_name,geoipcountrycode,geoIpCountryCode,group_id,group_map,group_name,ip_ngram,ip_search,isArchived,isInternal,iso_mtdt,iso_mtdt_search,isWithdrawn,last_name,name,ngram_query_search,ngram_simplequery_search,orphaned,parent_count,p_communities_id,p_communities_map,p_communities_name,p_group_id,p_group_map,p_group_name,range,rangeDescription,rangeDescription_ngram,rangeDescription_search,range_ngram,range_search,referrer_ngram,referrer_search,simple_query,simple_query_search,solr_update_time_stamp,storage_nb_of_bitstreams,storage_size,storage_statistics_type,subject_mtdt,subject_mtdt_search,text,userAgent_ngram,userAgent_search,version_id,workflowItemId&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Export a list of affiliations from the Initiatives community for Peter:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ dspace metadata-export -i 10568/115087 -f /tmp/2023-07-28-initiatives.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;cg.contributor.affiliation[en_US]&amp;#39;&lt;/span&gt; ~/Downloads/2023-07-28-initiatives.csv &lt;span style=&#34;color:#ae81ff&#34;&gt;\&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;&lt;/span&gt;  | sed -e 1d -e &amp;#39;s/^&amp;#34;//&amp;#39; -e &amp;#39;s/&amp;#34;$//&amp;#39; -e &amp;#39;s/||/\n/g&amp;#39; -e &amp;#39;/^$/d&amp;#39;            \&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  | sort | uniq -c | sort -hr                                              \&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  | awk &amp;#39;BEGIN { FS = &amp;#34;^[[:space:]]+[[:digit:]]+[[:space:]]+&amp;#34; } {print $2}&amp;#39;\&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  | sed -e &amp;#39;1i cg.contributor.affiliation&amp;#39; -e &amp;#39;s/^\(.*\)$/&amp;#34;\1&amp;#34;/&amp;#39;           \&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &amp;gt; /tmp/2023-07-28-initiatives-affiliations.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;This is a method I first used in 2023-01 to export affiliations ONLY used in items in the Initiatives community&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I did the same for authors and investors&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2023-07-29&#34;&gt;2023-07-29&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to look for missing Initiative collection mappings&lt;/li&gt;&#xA;&lt;li&gt;I found a bunch of locks waiting for many hours and killed them:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ psql &amp;lt; locks-age.sql | awk -F&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;|&amp;#34;&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;$9 ~ / [[:digit:]][1-9]:[[:digit:]]{2}:[[:digit:]]{2}\./ {print $10}&amp;#39;&lt;/span&gt; | sort -u | xargs kill&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;This looks for a pattern matching something like &lt;code&gt;11:30:48.598436&lt;/code&gt; in the age column (not 00:00:00) and kills them&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>June, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-06/</link>
      <pubDate>Fri, 02 Jun 2023 10:29:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-06/</guid>
      <description>&lt;h2 id=&#34;2023-06-02&#34;&gt;2023-06-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Spend some time testing my &lt;code&gt;post_bitstreams.py&lt;/code&gt; script to update thumbnails for items on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Interestingly I found an item with a JFIF thumbnail and another with a WebP thumbnail&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Meeting with Valentina, Stefano, and Sara about MODS metadata in CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They have experience with improving the MODS interface in MELSpace&amp;rsquo;s OAI-PMH for use with AGRIS and were curious if we could do the same in CGSpace&lt;/li&gt;&#xA;&lt;li&gt;From what I can see we need to upgrade the MODS schema from 3.1 to 3.7 and then just add a bunch of our fields to the crosswalk&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>May, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-05/</link>
      <pubDate>Wed, 03 May 2023 08:53:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-05/</guid>
      <description>&lt;h2 id=&#34;2023-05-03&#34;&gt;2023-05-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Alliance&amp;rsquo;s TIP team emailed me to ask about issues authenticating on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It seems their password expired, which is annoying&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I continued looking at the CGSpace subjects for the FAO / AGROVOC exercise that I started last week&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There are many of our subjects that would match if they added a &amp;ldquo;-&amp;rdquo; like &amp;ldquo;high yielding varieties&amp;rdquo; or used singular&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;Also I found at least two spelling mistakes, for example &amp;ldquo;decison support systems&amp;rdquo;, which would match if it was spelled correctly&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Work on cleaning, proofing, and uploading twenty-seven records for IFPRI to CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-04/</link>
      <pubDate>Sun, 02 Apr 2023 08:19:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-04/</guid>
      <description>&lt;h2 id=&#34;2023-04-02&#34;&gt;2023-04-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Run all system updates on CGSpace and reboot it&lt;/li&gt;&#xA;&lt;li&gt;I exported CGSpace to CSV to check for any missing Initiative collection mappings&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I also did a check for missing country/region mappings with csv-metadata-quality&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Start a harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>March, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-03/</link>
      <pubDate>Wed, 01 Mar 2023 07:58:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-03/</guid>
      <description>&lt;h2 id=&#34;2023-03-01&#34;&gt;2023-03-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Remove &lt;code&gt;cg.subject.wle&lt;/code&gt; and &lt;code&gt;cg.identifier.wletheme&lt;/code&gt; from CGSpace input form after confirming with IWMI colleagues that they no longer need them (WLE closed in 2021)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://salsa.debian.org/iso-codes-team/iso-codes/-/blob/main/CHANGELOG.md#4130-2023-02-28&#34;&gt;iso-codes 4.13.0 was released&lt;/a&gt;, which incorporates my changes to the common names for Iran, Laos, and Syria&lt;/li&gt;&#xA;&lt;li&gt;I finally got through with porting the input form from DSpace 6 to DSpace 7&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>February, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-02/</link>
      <pubDate>Wed, 01 Feb 2023 10:57:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-02/</guid>
      <description>&lt;h2 id=&#34;2023-02-01&#34;&gt;2023-02-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export CGSpace to cross check the DOI metadata with Crossref&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I want to try to expand my use of their data to journals, publishers, volumes, issues, etc&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>January, 2023</title>
      <link>http://localhost:1313/cgspace-notes/2023-01/</link>
      <pubDate>Sun, 01 Jan 2023 08:44:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2023-01/</guid>
      <description>&lt;h2 id=&#34;2023-01-01&#34;&gt;2023-01-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Apply some more ORCID identifiers to items on CGSpace using my &lt;code&gt;2022-09-22-add-orcids.csv&lt;/code&gt; file&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I want to update all ORCID names and refresh them in the database&lt;/li&gt;&#xA;&lt;li&gt;I see we have some new ones that aren&amp;rsquo;t in our list if I combine with this file:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>December, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-12/</link>
      <pubDate>Thu, 01 Dec 2022 08:52:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-12/</guid>
      <description>&lt;h2 id=&#34;2022-12-01&#34;&gt;2022-12-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix some incorrect regions on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I exported the CCAFS and IITA communities, extracted just the country and region columns, then ran them through csv-metadata-quality to fix the regions&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Add a few more authors to my CSV with author names and ORCID identifiers and tag 283 items!&lt;/li&gt;&#xA;&lt;li&gt;Replace &amp;ldquo;East Asia&amp;rdquo; with &amp;ldquo;Eastern Asia&amp;rdquo; region on CGSpace (UN M.49 region)&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>November, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-11/</link>
      <pubDate>Tue, 01 Nov 2022 09:11:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-11/</guid>
      <description>&lt;h2 id=&#34;2022-11-01&#34;&gt;2022-11-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Last night I re-synced DSpace 7 Test from CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I also updated all my local &lt;code&gt;7_x-dev&lt;/code&gt; branches on the latest upstreams&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I spent some time updating the authorizations in Alliance collections&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I want to make sure they use groups instead of individuals where possible!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I reverted the Cocoon autosave change because it was more of a nuissance that Peter can&amp;rsquo;t upload CSVs from the web interface and is a very low severity security issue&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>October, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-10/</link>
      <pubDate>Sat, 01 Oct 2022 19:45:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-10/</guid>
      <description>&lt;h2 id=&#34;2022-10-01&#34;&gt;2022-10-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start a harvest on AReS last night&lt;/li&gt;&#xA;&lt;li&gt;Yesterday I realized how to use &lt;a href=&#34;https://im4java.sourceforge.net/docs/dev-guide.html&#34;&gt;GraphicsMagick with im4java&lt;/a&gt; and I want to re-visit some of my thumbnail tests&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I&amp;rsquo;m also interested in libvips support via jVips, though last time I checked it was only for Java 8&lt;/li&gt;&#xA;&lt;li&gt;I filed &lt;a href=&#34;https://github.com/criteo/JVips/issues/141&#34;&gt;an issue to ask about Java 11+ support&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>September, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-09/</link>
      <pubDate>Thu, 01 Sep 2022 09:41:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-09/</guid>
      <description>&lt;h2 id=&#34;2022-09-01&#34;&gt;2022-09-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A bit of work on the &amp;ldquo;Mapping CG Core–CGSpace–MEL–MARLO Types&amp;rdquo; spreadsheet&lt;/li&gt;&#xA;&lt;li&gt;I tested an item submission on DSpace Test with the Cocoon &lt;code&gt;org.apache.cocoon.uploads.autosave=false&lt;/code&gt; change&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The submission works as expected&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Start debugging some region-related issues with csv-metadata-quality&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I created a new test file &lt;code&gt;test-geography.csv&lt;/code&gt; with some different scenarios&lt;/li&gt;&#xA;&lt;li&gt;I also fixed a few bugs and improved the region-matching logic&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>August, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-08/</link>
      <pubDate>Mon, 01 Aug 2022 10:22:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-08/</guid>
      <description>&lt;h2 id=&#34;2022-08-01&#34;&gt;2022-08-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Our request to add &lt;a href=&#34;https://github.com/spdx/license-list-XML/issues/1525&#34;&gt;CC-BY-3.0-IGO to SPDX&lt;/a&gt; was approved a few weeks ago&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>July, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-07/</link>
      <pubDate>Sat, 02 Jul 2022 14:07:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-07/</guid>
      <description>&lt;h2 id=&#34;2022-07-02&#34;&gt;2022-07-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I learned how to use the Levenshtein functions in PostgreSQL&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The thing is that there is a limit of 255 characters for these functions in PostgreSQL so you need to truncate the strings before comparing&lt;/li&gt;&#xA;&lt;li&gt;Also, the trgm functions I&amp;rsquo;ve used before are case insensitive, but Levenshtein is not, so you need to make sure to lower case both strings first&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>June, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-06/</link>
      <pubDate>Mon, 06 Jun 2022 09:01:36 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-06/</guid>
      <description>&lt;h2 id=&#34;2022-06-06&#34;&gt;2022-06-06&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Look at the Solr statistics on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I see 167,000 hits from a bunch of Microsoft IPs with reverse DNS &amp;ldquo;msnbot-&amp;rdquo; using the Solr query &lt;code&gt;dns:*msnbot* AND dns:*.msn.com&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;I purged these first so I could see the other &amp;ldquo;real&amp;rdquo; IPs in the Solr facets&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I see 47,500 hits from 80.248.237.167 on a data center ISP in Sweden, using a normal user agent&lt;/li&gt;&#xA;&lt;li&gt;I see 13,000 hits from 163.237.216.11 on a data center ISP in Australia, using a normal user agent&lt;/li&gt;&#xA;&lt;li&gt;I see 7,300 hits from 208.185.238.57 from Britanica, using a normal user agent&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There seem to be many more of these:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>May, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-05/</link>
      <pubDate>Wed, 04 May 2022 09:13:39 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-05/</guid>
      <description>&lt;h2 id=&#34;2022-05-04&#34;&gt;2022-05-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I found a few more IPs making requests using the shady Chrome 44 user agent in the last few days so I will add them to the block list too:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;18.207.136.176&lt;/li&gt;&#xA;&lt;li&gt;185.189.36.248&lt;/li&gt;&#xA;&lt;li&gt;50.118.223.78&lt;/li&gt;&#xA;&lt;li&gt;52.70.76.123&lt;/li&gt;&#xA;&lt;li&gt;3.236.10.11&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Looking at the Solr statistics for 2022-04&#xA;&lt;ul&gt;&#xA;&lt;li&gt;52.191.137.59 is Microsoft, but they are using a normal user agent and making tens of thousands of requests&lt;/li&gt;&#xA;&lt;li&gt;64.39.98.62 is owned by Qualys, and all their requests are probing for /etc/passwd etc&lt;/li&gt;&#xA;&lt;li&gt;185.192.69.15 is in the Netherlands and is using a normal user agent, but making excessive automated HTTP requests to paths forbidden in robots.txt&lt;/li&gt;&#xA;&lt;li&gt;157.55.39.159 is owned by Microsoft and identifies as bingbot so I don&amp;rsquo;t know why its requests were logged in Solr&lt;/li&gt;&#xA;&lt;li&gt;52.233.67.176 is owned by Microsoft and uses a normal user agent, but making excessive automated HTTP requests&lt;/li&gt;&#xA;&lt;li&gt;157.55.39.144 is owned by Microsoft and uses a normal user agent, but making excessive automated HTTP requests&lt;/li&gt;&#xA;&lt;li&gt;207.46.13.177 is owned by Microsoft and identifies as bingbot so I don&amp;rsquo;t know why its requests were logged in Solr&lt;/li&gt;&#xA;&lt;li&gt;If I query Solr for &lt;code&gt;time:2022-04* AND dns:*msnbot* AND dns:*.msn.com.&lt;/code&gt; I see a handful of IPs that made 41,000 requests&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I purged 93,974 hits from these IPs using my &lt;code&gt;check-spider-ip-hits.sh&lt;/code&gt; script&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-04/</link>
      <pubDate>Fri, 01 Apr 2022 10:53:39 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-04/</guid>
      <description>&lt;h2 id=&#34;2022-04-01&#34;&gt;2022-04-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I did G1GC tests on DSpace Test (linode26) to compliment the CMS tests I did yesterday&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The Discovery indexing took this long:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;real    334m33.625s&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;user    227m51.331s&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;sys     3m43.037s&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;2022-04-04&#34;&gt;2022-04-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start a full harvest on AReS&lt;/li&gt;&#xA;&lt;li&gt;Help Marianne with submit/approve access on a new collection on CGSpace&lt;/li&gt;&#xA;&lt;li&gt;Go back in Gaia&amp;rsquo;s batch reports to find records that she indicated for replacing on CGSpace (ie, those with better new copies, new versions, etc)&lt;/li&gt;&#xA;&lt;li&gt;Looking at the Solr statistics for 2022-03 on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I see 54.229.218.204 on Amazon AWS made 49,000 requests, some of which with this user agent: &lt;code&gt;Apache-HttpClient/4.5.9 (Java/1.8.0_322)&lt;/code&gt;, and many others with a normal browser agent, so that&amp;rsquo;s fishy!&lt;/li&gt;&#xA;&lt;li&gt;The DSpace agent pattern &lt;code&gt;http.?agent&lt;/code&gt; seems to have caught the first ones, but I&amp;rsquo;ll purge the IP ones&lt;/li&gt;&#xA;&lt;li&gt;I see 40.77.167.80 is Bing or MSN Bot, but using a normal browser user agent, and if I search Solr for &lt;code&gt;dns:*msnbot* AND dns:*.msn.com.&lt;/code&gt; I see over 100,000, which is a problem I noticed a few months ago too&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;I extracted the MSN Bot IPs from Solr using an IP facet, then used the &lt;code&gt;check-spider-ip-hits.sh&lt;/code&gt; script to purge them&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2022-04-10&#34;&gt;2022-04-10&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start a full harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2022-04-13&#34;&gt;2022-04-13&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;UptimeRobot mailed to say that CGSpace was down&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I looked and found the load at 44&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;There seem to be a lot of locks from the XMLUI:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ psql -c &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;SELECT * FROM pg_locks pl LEFT JOIN pg_stat_activity psa ON pl.pid = psa.pid;&amp;#39;&lt;/span&gt; | grep -o -E &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;(dspaceWeb|dspaceApi)&amp;#39;&lt;/span&gt; | sort | uniq -c | sort -n&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   3173 dspaceWeb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Looking at the top IPs in nginx&amp;rsquo;s access log one IP in particular stands out:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    941 66.249.66.222&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1224 95.108.213.28&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   2074 157.90.209.76&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   3064 66.249.66.221&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  95743 185.192.69.15&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;185.192.69.15 is in the UK&lt;/li&gt;&#xA;&lt;li&gt;I added a block for that IP in nginx and the load went down&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2022-04-16&#34;&gt;2022-04-16&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2022-04-18&#34;&gt;2022-04-18&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I woke up to several notices from UptimeRobot that CGSpace had gone down and up in the night (of course I&amp;rsquo;m on holiday out of the country for Easter)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I see there are many locks in use from the XMLUI:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ psql -c &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;SELECT * FROM pg_locks pl LEFT JOIN pg_stat_activity psa ON pl.pid = psa.pid;&amp;#39;&lt;/span&gt; | grep -o -E &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;(dspaceWeb|dspaceApi)&amp;#39;&lt;/span&gt; | sort | uniq -c&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   8932 dspaceWeb&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Looking at the top IPs making requests it seems they are Yandex, bingbot, and Googlebot:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# cat /var/log/nginx/access.log /var/log/nginx/access.log.1 | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; | sort | uniq -c | sort -h&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    752 69.162.124.231&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    759 66.249.64.213&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    864 66.249.66.222&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    905 2a01:4f8:221:f::2&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1013 84.33.2.97&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1201 157.55.39.159&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1204 157.55.39.144&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1209 157.55.39.102&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1217 157.55.39.161&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1252 207.46.13.177&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   1274 157.55.39.162&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   2553 66.249.66.221&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   2941 95.108.213.28&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;One IP is using a stange user agent though:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;84.33.2.97 - - [18/Apr/2022:00:20:38 +0200] &amp;#34;GET /bitstream/handle/10568/109581/Banana_Blomme%20_2020.pdf.jpg HTTP/1.1&amp;#34; 404 10890 &amp;#34;-&amp;#34; &amp;#34;SomeRandomText&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Overall, it seems we had 17,000 unique IPs connecting in the last nine hours (currently 9:14AM and log file rolled over at 00:00):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# cat /var/log/nginx/access.log | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;17314&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;That&amp;rsquo;s a lot of unique IPs, and I see some patterns of IPs in China making ten to twenty requests each&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The ISPs I&amp;rsquo;ve seen so far are ChinaNet and China Unicom&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I extracted all the IPs from today and resolved them:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# cat /var/log/nginx/access.log | awk &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; | sort | uniq &amp;gt; /tmp/2022-04-18-ips.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./ilri/resolve-addresses-geoip2.py -i /tmp/2022-04-18-ips.txt -o /tmp/2022-04-18-ips.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;The top ASNs by IP are:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt; /tmp/2022-04-18-ips.csv | sed 1d | sort | uniq -c | sort -n | tail -n &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt; &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    102 GOOGLE&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    139 Maxihost LTDA&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    165 AMAZON-02&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    393 &amp;#34;China Mobile Communications Group Co., Ltd.&amp;#34;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    473 AMAZON-AES&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    616 China Mobile communications corporation&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    642 M247 Ltd&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   2336 HostRoyale Technologies Pvt Ltd&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   4556 Chinanet&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   5527 CHINA UNICOM China169 Backbone&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt; /tmp/2022-04-18-ips.csv | sed 1d | sort | uniq -c | sort -n | tail -n &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    139 262287&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    165 16509&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    180 204287&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    393 9808&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    473 14618&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    615 56041&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    642 9009&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   2156 203020&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   4556 4134&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;   5527 4837&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I spot checked a few IPs from each of these and they are definitely just making bullshit requests to Discovery and HTML sitemap etc&lt;/li&gt;&#xA;&lt;li&gt;I will download the IP blocks for each ASN except Google and Amazon and ban them&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ wget https://asn.ipinfo.app/api/text/nginx/AS4837 https://asn.ipinfo.app/api/text/nginx/AS4134 https://asn.ipinfo.app/api/text/nginx/AS203020 https://asn.ipinfo.app/api/text/nginx/AS9009 https://asn.ipinfo.app/api/text/nginx/AS56041 https://asn.ipinfo.app/api/text/nginx/AS9808&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ cat AS* | sed -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^$/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^#/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^{/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/deny //&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/;//&amp;#39;&lt;/span&gt; | sort | uniq | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;20296&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I extracted the IPv4 and IPv6 networks:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ cat AS* | sed -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^$/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^#/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^{/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/deny //&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/;//&amp;#39;&lt;/span&gt; | grep &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;:&amp;#34;&lt;/span&gt; | sort &amp;gt; /tmp/ipv6-networks.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ cat AS* | sed -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^$/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^#/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;/^{/d&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/deny //&amp;#39;&lt;/span&gt; -e &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/;//&amp;#39;&lt;/span&gt; | grep -v &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;:&amp;#34;&lt;/span&gt; | sort &amp;gt; /tmp/ipv4-networks.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I suspect we need to aggregate these networks since they are so many and nftables doesn&amp;rsquo;t like it when they overlap:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ wc -l /tmp/ipv4-networks.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;15464 /tmp/ipv4-networks.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ aggregate6 /tmp/ipv4-networks.txt | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;2781&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ wc -l /tmp/ipv6-networks.txt             &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;4833 /tmp/ipv6-networks.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ aggregate6 /tmp/ipv6-networks.txt | wc -l&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;338&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I deployed these lists on CGSpace, ran all updates, and rebooted the server&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This list is SURELY too broad because we will block legitimate users in China&amp;hellip; but right now how can I discern?&lt;/li&gt;&#xA;&lt;li&gt;Also, I need to purge the hits from these 14,000 IPs in Solr when I get time&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Looking back at the Munin graphs a few hours later I see this was indeed some kind of spike that was out of the ordinary:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/cgspace-notes/2022/04/postgres_connections_ALL-day.png&#34; alt=&#34;PostgreSQL connections day&#34;&gt;&#xA;&lt;img src=&#34;http://localhost:1313/cgspace-notes/2022/04/jmx_dspace_sessions-day.png&#34; alt=&#34;DSpace sessions day&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>March, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-03/</link>
      <pubDate>Tue, 01 Mar 2022 16:46:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-03/</guid>
      <description>&lt;h2 id=&#34;2022-03-01&#34;&gt;2022-03-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Send Gaia the last batch of potential duplicates for items 701 to 980:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c id,dc.title,dcterms.issued,dcterms.type ~/Downloads/2022-03-01-CGSpace-TAC-ICW-batch4-701-980.csv &amp;gt; /tmp/tac4.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./ilri/check-duplicates.py -i /tmp/tac4.csv -db dspace -u dspace -p &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;fuuu&amp;#39;&lt;/span&gt; -o /tmp/2022-03-01-tac-batch4-701-980.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c id,filename ~/Downloads/2022-03-01-CGSpace-TAC-ICW-batch4-701-980.csv &amp;gt; /tmp/tac4-filenames.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvjoin -c id /tmp/2022-03-01-tac-batch4-701-980.csv /tmp/tac4-filenames.csv &amp;gt; /tmp/2022-03-01-tac-batch4-701-980-filenames.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>February, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-02/</link>
      <pubDate>Tue, 01 Feb 2022 14:06:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-02/</guid>
      <description>&lt;h2 id=&#34;2022-02-01&#34;&gt;2022-02-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Meeting with Peter and Abenet about CGSpace in the One CGIAR&#xA;&lt;ul&gt;&#xA;&lt;li&gt;We agreed to buy $5,000 worth of credits from Atmire for future upgrades&lt;/li&gt;&#xA;&lt;li&gt;We agreed to move CRPs and non-CGIAR communities off the home page, as well as some other things for the CGIAR System Organization&lt;/li&gt;&#xA;&lt;li&gt;We agreed to make a Discovery facet for CGIAR Action Areas above the existing CGIAR Impact Areas one&lt;/li&gt;&#xA;&lt;li&gt;We agreed to try to do more alignment of affiliations/funders with ROR&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>January, 2022</title>
      <link>http://localhost:1313/cgspace-notes/2022-01/</link>
      <pubDate>Sat, 01 Jan 2022 15:20:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2022-01/</guid>
      <description>&lt;h2 id=&#34;2022-01-01&#34;&gt;2022-01-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Start a full harvest on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>December, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-12/</link>
      <pubDate>Wed, 01 Dec 2021 16:07:07 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-12/</guid>
      <description>&lt;h2 id=&#34;2021-12-01&#34;&gt;2021-12-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Atmire merged some changes I had submitted to the COUNTER-Robots project&lt;/li&gt;&#xA;&lt;li&gt;I updated our local spider user agents and then re-ran the list with my &lt;code&gt;check-spider-hits.sh&lt;/code&gt; script on CGSpace:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./ilri/check-spider-hits.sh -f /tmp/agents -p  &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Purging 1989 hits from The Knowledge AI in statistics&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Purging 1235 hits from MaCoCu in statistics&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Purging 455 hits from WhatsApp in statistics&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#960050;background-color:#1e0010&#34;&gt;&lt;/span&gt;Total number of bot hits purged: 3679&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>November, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-11/</link>
      <pubDate>Tue, 02 Nov 2021 22:27:07 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-11/</guid>
      <description>&lt;h2 id=&#34;2021-11-02&#34;&gt;2021-11-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I experimented with manually sharding the Solr statistics on DSpace Test&lt;/li&gt;&#xA;&lt;li&gt;First I exported all the 2019 stats from CGSpace:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./run.sh -s http://localhost:8081/solr/statistics -f &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;time:2019-*&amp;#39;&lt;/span&gt; -a export -o statistics-2019.json -k uid&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ zstd statistics-2019.json&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>October, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-10/</link>
      <pubDate>Fri, 01 Oct 2021 11:14:07 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-10/</guid>
      <description>&lt;h2 id=&#34;2021-10-01&#34;&gt;2021-10-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export all affiliations on CGSpace and run them against the latest RoR data dump:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;localhost/dspace63= &amp;gt; \COPY (SELECT DISTINCT text_value as &amp;#34;cg.contributor.affiliation&amp;#34;, count(*) FROM metadatavalue WHERE dspace_object_id IN (SELECT uuid FROM item) AND metadata_field_id = 211 GROUP BY text_value ORDER BY count DESC) to /tmp/2021-10-01-affiliations.csv WITH CSV HEADER;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvcut -c &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt; /tmp/2021-10-01-affiliations.csv | sed 1d &amp;gt; /tmp/2021-10-01-affiliations.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ ./ilri/ror-lookup.py -i /tmp/2021-10-01-affiliations.txt -r 2021-09-23-ror-data.json -o /tmp/2021-10-01-affili&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;ations-matching.csv&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ csvgrep -c matched -m true /tmp/2021-10-01-affiliations-matching.csv | sed 1d | wc -l &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;1879&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ wc -l /tmp/2021-10-01-affiliations.txt &#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;7100 /tmp/2021-10-01-affiliations.txt&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;So we have 1879/7100 (26.46%) matching already&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>September, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-09/</link>
      <pubDate>Wed, 01 Sep 2021 09:14:07 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-09/</guid>
      <description>&lt;h2 id=&#34;2021-09-02&#34;&gt;2021-09-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Troubleshooting the missing Altmetric scores on AReS&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Turns out that I didn&amp;rsquo;t actually fix them last month because the check for &lt;code&gt;content.altmetric&lt;/code&gt; still exists, and I can&amp;rsquo;t access the DOIs using &lt;code&gt;_h.source.DOI&lt;/code&gt; for some reason&lt;/li&gt;&#xA;&lt;li&gt;I can access all other kinds of item metadata using the Elasticsearch label, but not DOI!!!&lt;/li&gt;&#xA;&lt;li&gt;I will change &lt;code&gt;DOI&lt;/code&gt; to &lt;code&gt;tomato&lt;/code&gt; in the repository setup and start a re-harvest&amp;hellip; I need to see if this is some kind of reserved word or something&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;Even as &lt;code&gt;tomato&lt;/code&gt; I can&amp;rsquo;t access that field as &lt;code&gt;_h.source.tomato&lt;/code&gt; in Angular, but it does work as a filter source&amp;hellip; sigh&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I&amp;rsquo;m having problems using the OpenRXV API&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The syntax Moayad showed me last month doesn&amp;rsquo;t seem to honor the search query properly&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>August, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-08/</link>
      <pubDate>Sun, 01 Aug 2021 09:01:07 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-08/</guid>
      <description>&lt;h2 id=&#34;2021-08-01&#34;&gt;2021-08-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Update Docker images on AReS server (linode20) and reboot the server:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;# docker images | grep -v ^REPO | sed &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;s/ \+/:/g&amp;#39;&lt;/span&gt; | cut -d: -f1,2 | grep -v none | xargs -L1 docker pull&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;I decided to upgrade linode20 from Ubuntu 18.04 to 20.04&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>July, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-07/</link>
      <pubDate>Thu, 01 Jul 2021 08:53:07 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-07/</guid>
      <description>&lt;h2 id=&#34;2021-07-01&#34;&gt;2021-07-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export another list of ALL subjects on CGSpace, including AGROVOC and non-AGROVOC for Enrico:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;localhost/dspace63= &amp;gt; \COPY (SELECT DISTINCT LOWER(text_value) AS subject, count(*) FROM metadatavalue WHERE dspace_object_id in (SELECT dspace_object_id FROM item) AND metadata_field_id IN (119, 120, 127, 122, 128, 125, 135, 203, 208, 210, 215, 123, 236, 242, 187) GROUP BY subject ORDER BY count DESC) to /tmp/2021-07-01-all-subjects.csv WITH CSV HEADER;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;COPY 20994&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>June, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-06/</link>
      <pubDate>Tue, 01 Jun 2021 10:51:07 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-06/</guid>
      <description>&lt;h2 id=&#34;2021-06-01&#34;&gt;2021-06-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;IWMI notified me that AReS was down with an HTTP 502 error&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Looking at UptimeRobot I see it has been down for 33 hours, but I never got a notification&lt;/li&gt;&#xA;&lt;li&gt;I don&amp;rsquo;t see anything in the Elasticsearch container logs, or the systemd journal on the host, but I notice that the &lt;code&gt;angular_nginx&lt;/code&gt; container isn&amp;rsquo;t running&lt;/li&gt;&#xA;&lt;li&gt;I simply started it and AReS was running again:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>May, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-05/</link>
      <pubDate>Sun, 02 May 2021 09:50:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-05/</guid>
      <description>&lt;h2 id=&#34;2021-05-01&#34;&gt;2021-05-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I looked at the top user agents and IPs in the Solr statistics for last month and I see these user agents:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&amp;ldquo;RI/1.0&amp;rdquo;, 1337&lt;/li&gt;&#xA;&lt;li&gt;&amp;ldquo;Microsoft Office Word 2014&amp;rdquo;, 941&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I will add the RI/1.0 pattern to our DSpace agents overload and purge them from Solr (we had previously seen this agent with 9,000 hits or so in 2020-09), but I think I will leave the Microsoft Word one&amp;hellip; as that&amp;rsquo;s an actual user&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-04/</link>
      <pubDate>Thu, 01 Apr 2021 09:50:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-04/</guid>
      <description>&lt;h2 id=&#34;2021-04-01&#34;&gt;2021-04-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I wrote a script to query Sherpa&amp;rsquo;s API for our ISSNs: &lt;code&gt;sherpa-issn-lookup.py&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I&amp;rsquo;m curious to see how the results compare with the results from Crossref yesterday&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;AReS Explorer was down since this morning, I didn&amp;rsquo;t see anything in the systemd journal&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I simply took everything down with docker-compose and then back up, and then it was OK&lt;/li&gt;&#xA;&lt;li&gt;Perhaps one of the containers crashed, I should have looked closer but I was in a hurry&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>March, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-03/</link>
      <pubDate>Mon, 01 Mar 2021 10:13:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-03/</guid>
      <description>&lt;h2 id=&#34;2021-03-01&#34;&gt;2021-03-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Discuss some OpenRXV issues with Abdullah from CodeObia&#xA;&lt;ul&gt;&#xA;&lt;li&gt;He&amp;rsquo;s trying to work on the DSpace 6+ metadata schema autoimport using the DSpace 6+ REST API&lt;/li&gt;&#xA;&lt;li&gt;Also, we found some issues building and running OpenRXV currently due to ecosystem shift in the Node.js dependencies&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>CGSpace CG Core v2 Migration</title>
      <link>http://localhost:1313/cgspace-notes/cgspace-cgcorev2-migration/</link>
      <pubDate>Sun, 21 Feb 2021 13:27:35 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/cgspace-cgcorev2-migration/</guid>
      <description>&lt;p&gt;Changes to CGSpace metadata fields to align more with DC, QDC, and DCTERMS as well as CG Core v2. Implemented on 2021-02-21.&lt;/p&gt;&#xA;&lt;p&gt;With reference to &lt;a href=&#34;https://agriculturalsemantics.github.io/cg-core/cgcore.html&#34;&gt;CG Core v2 draft standard&lt;/a&gt; by Marie-Angélique as well as &lt;a href=&#34;http://www.dublincore.org/specifications/dublin-core/dcmi-terms/&#34;&gt;DCMI DCTERMS&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>February, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-02/</link>
      <pubDate>Mon, 01 Feb 2021 10:13:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-02/</guid>
      <description>&lt;h2 id=&#34;2021-02-01&#34;&gt;2021-02-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Abenet said that CIP found more duplicate records in their export from AReS&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I re-opened &lt;a href=&#34;https://github.com/ilri/OpenRXV/issues/67&#34;&gt;the issue&lt;/a&gt; on OpenRXV where we had previously noticed this&lt;/li&gt;&#xA;&lt;li&gt;The shared link where the duplicates are is here: &lt;a href=&#34;https://cgspace.cgiar.org/explorer/shared/heEOz3YBnXdK69bR2ra6&#34;&gt;https://cgspace.cgiar.org/explorer/shared/heEOz3YBnXdK69bR2ra6&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I had a call with CodeObia to discuss the work on OpenRXV&lt;/li&gt;&#xA;&lt;li&gt;Check the results of the AReS harvesting from last night:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-console&#34; data-lang=&#34;console&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;$ curl -s &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;http://localhost:9200/openrxv-items-temp/_count?q=*&amp;amp;pretty&amp;#39;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;{&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &amp;#34;count&amp;#34; : 100875,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &amp;#34;_shards&amp;#34; : {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;#34;total&amp;#34; : 1,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;#34;successful&amp;#34; : 1,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;#34;skipped&amp;#34; : 0,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &amp;#34;failed&amp;#34; : 0&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  }&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>January, 2021</title>
      <link>http://localhost:1313/cgspace-notes/2021-01/</link>
      <pubDate>Sun, 03 Jan 2021 10:13:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2021-01/</guid>
      <description>&lt;h2 id=&#34;2021-01-03&#34;&gt;2021-01-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Peter notified me that some filters on AReS were broken again&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It&amp;rsquo;s the same issue with the field names getting &lt;code&gt;.keyword&lt;/code&gt; appended to the end that I already &lt;a href=&#34;https://github.com/ilri/OpenRXV/issues/66&#34;&gt;filed an issue on OpenRXV about last month&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;I fixed the broken filters (careful to not edit any others, lest they break too!)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Fix an issue with start page number for the DSpace REST API and statistics API in OpenRXV&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The start page had been &amp;ldquo;1&amp;rdquo; in the UI, but in the backend they were doing some gymnastics to adjust to the zero-based offset/limit/page of the DSpace REST API and the statistics API&lt;/li&gt;&#xA;&lt;li&gt;I adjusted it to default to 0 and added a note to the admin screen&lt;/li&gt;&#xA;&lt;li&gt;I realized that this issue was actually causing the first page of 100 statistics to be missing&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;For example, &lt;a href=&#34;https://cgspace.cgiar.org/handle/10568/66839&#34;&gt;this item&lt;/a&gt; has 51 views on CGSpace, but 0 on AReS&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>December, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-12/</link>
      <pubDate>Tue, 01 Dec 2020 11:32:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-12/</guid>
      <description>&lt;h2 id=&#34;2020-12-01&#34;&gt;2020-12-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Atmire responded about the issue with duplicate data in our Solr statistics&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They noticed that some records in the statistics-2015 core haven&amp;rsquo;t been migrated with the AtomicStatisticsUpdateCLI tool yet and assumed that I haven&amp;rsquo;t migrated any of the records yet&lt;/li&gt;&#xA;&lt;li&gt;That&amp;rsquo;s strange, as I checked all ten cores and 2015 is the only one with some unmigrated documents, as according to the &lt;code&gt;cua_version&lt;/code&gt; field&lt;/li&gt;&#xA;&lt;li&gt;I started processing those (about 411,000 records):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>CGSpace DSpace 6 Upgrade</title>
      <link>http://localhost:1313/cgspace-notes/cgspace-dspace6-upgrade/</link>
      <pubDate>Sun, 15 Nov 2020 13:27:35 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/cgspace-dspace6-upgrade/</guid>
      <description>&lt;p&gt;Notes about the DSpace 6 upgrade on CGSpace in 2020-11.&lt;/p&gt;</description>
    </item>
    <item>
      <title>November, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-11/</link>
      <pubDate>Sun, 01 Nov 2020 13:11:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-11/</guid>
      <description>&lt;h2 id=&#34;2020-11-01&#34;&gt;2020-11-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Continue with processing the statistics-2019 Solr core with the AtomicStatisticsUpdateCLI tool on DSpace Test&#xA;&lt;ul&gt;&#xA;&lt;li&gt;So far we&amp;rsquo;ve spent at least fifty hours to process the statistics and statistics-2019 core&amp;hellip; wow.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>October, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-10/</link>
      <pubDate>Tue, 06 Oct 2020 16:55:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-10/</guid>
      <description>&lt;h2 id=&#34;2020-10-06&#34;&gt;2020-10-06&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Add tests for the new &lt;code&gt;/items&lt;/code&gt; POST handlers to the DSpace 6.x branch of my &lt;a href=&#34;https://github.com/ilri/dspace-statistics-api/tree/v6_x&#34;&gt;dspace-statistics-api&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It took a bit of extra work because I had to learn how to mock the responses for when Solr is not available&lt;/li&gt;&#xA;&lt;li&gt;Tag and release version 1.3.0 on GitHub: &lt;a href=&#34;https://github.com/ilri/dspace-statistics-api/releases/tag/v1.3.0&#34;&gt;https://github.com/ilri/dspace-statistics-api/releases/tag/v1.3.0&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Trying to test the changes Atmire sent last week but I had to re-create my local database from a recent CGSpace dump&#xA;&lt;ul&gt;&#xA;&lt;li&gt;During the FlywayDB migration I got an error:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>September, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-09/</link>
      <pubDate>Wed, 02 Sep 2020 15:35:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-09/</guid>
      <description>&lt;h2 id=&#34;2020-09-02&#34;&gt;2020-09-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Replace Marissa van Epp for Rhys Bucknall in the CCAFS groups on CGSpace because Marissa no longer works at CCAFS&lt;/li&gt;&#xA;&lt;li&gt;The AReS Explorer hasn&amp;rsquo;t updated its index since 2020-08-22 when I last forced it&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I restarted it again now and told Moayad that the automatic indexing isn&amp;rsquo;t working&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Add &lt;code&gt;Alliance of Bioversity International and CIAT&lt;/code&gt; to affiliations on CGSpace&lt;/li&gt;&#xA;&lt;li&gt;Abenet told me that the general search text on AReS doesn&amp;rsquo;t get reset when you use the &amp;ldquo;Reset Filters&amp;rdquo; button&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I filed a bug on OpenRXV: &lt;a href=&#34;https://github.com/ilri/OpenRXV/issues/39&#34;&gt;https://github.com/ilri/OpenRXV/issues/39&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I filed an issue on OpenRXV to make some minor edits to the admin UI: &lt;a href=&#34;https://github.com/ilri/OpenRXV/issues/40&#34;&gt;https://github.com/ilri/OpenRXV/issues/40&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>August, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-08/</link>
      <pubDate>Sun, 02 Aug 2020 15:35:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-08/</guid>
      <description>&lt;h2 id=&#34;2020-08-02&#34;&gt;2020-08-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I spent a few days working on a Java-based curation task to tag items with ISO 3166-1 Alpha2 country codes based on their &lt;code&gt;cg.coverage.country&lt;/code&gt; text values&#xA;&lt;ul&gt;&#xA;&lt;li&gt;It looks up the names in ISO 3166-1 first, and then in our CGSpace countries mapping (which has five or so of Peter&amp;rsquo;s preferred &amp;ldquo;display&amp;rdquo; country names)&lt;/li&gt;&#xA;&lt;li&gt;It implements a &amp;ldquo;force&amp;rdquo; mode too that will clear existing country codes and re-tag everything&lt;/li&gt;&#xA;&lt;li&gt;It is class based so I can easily add support for other vocabularies, and the technique could even be used for organizations with mappings to ROR and Clarisa&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>July, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-07/</link>
      <pubDate>Wed, 01 Jul 2020 10:53:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-07/</guid>
      <description>&lt;h2 id=&#34;2020-07-01&#34;&gt;2020-07-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;A few users noticed that CGSpace wasn&amp;rsquo;t loading items today, item pages seem blank&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I looked at the PostgreSQL locks but they don&amp;rsquo;t seem unusual&lt;/li&gt;&#xA;&lt;li&gt;I guess this is the same &amp;ldquo;blank item page&amp;rdquo; issue that we had a few times in 2019 that we never solved&lt;/li&gt;&#xA;&lt;li&gt;I restarted Tomcat and PostgreSQL and the issue was gone&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Since I was restarting Tomcat anyways I decided to redeploy the latest changes from the &lt;code&gt;5_x-prod&lt;/code&gt; branch and I added a note about COVID-19 items to the CGSpace frontpage at Peter&amp;rsquo;s request&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>June, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-06/</link>
      <pubDate>Mon, 01 Jun 2020 13:55:39 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-06/</guid>
      <description>&lt;h2 id=&#34;2020-06-01&#34;&gt;2020-06-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I tried to run the &lt;code&gt;AtomicStatisticsUpdateCLI&lt;/code&gt; CUA migration script on DSpace Test (linode26) again and it is still going very slowly and has tons of errors like I noticed yesterday&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I sent Atmire the dspace.log from today and told them to log into the server to debug the process&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;In other news, I checked the statistics API on DSpace 6 and it&amp;rsquo;s working&lt;/li&gt;&#xA;&lt;li&gt;I tried to build the OAI registry on the freshly migrated DSpace 6 on DSpace Test and I get an error:&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>May, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-05/</link>
      <pubDate>Sat, 02 May 2020 09:52:04 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-05/</guid>
      <description>&lt;h2 id=&#34;2020-05-02&#34;&gt;2020-05-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Peter said that CTA is having problems submitting an item to CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Looking at the PostgreSQL stats it seems to be the same issue that Tezira was having last week, as I see the number of connections in &amp;lsquo;idle in transaction&amp;rsquo; and &amp;lsquo;waiting for lock&amp;rsquo; state are increasing again&lt;/li&gt;&#xA;&lt;li&gt;I see that CGSpace (linode18) is still using PostgreSQL JDBC driver version 42.2.11, and there were some bugs related to transactions fixed in 42.2.12 (which I had updated in the Ansible playbooks, but not deployed yet)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-04/</link>
      <pubDate>Thu, 02 Apr 2020 10:53:24 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-04/</guid>
      <description>&lt;h2 id=&#34;2020-04-02&#34;&gt;2020-04-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Maria asked me to update Charles Staver&amp;rsquo;s ORCID iD in the submission template and on CGSpace, as his name was lower case before, and now he has corrected it&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I updated the fifty-eight existing items on CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Looking into the items Udana had asked about last week that were missing Altmetric donuts:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hdl.handle.net/10568/103225&#34;&gt;The first&lt;/a&gt; is still missing its DOI, so I added it and &lt;a href=&#34;https://twitter.com/mralanorth/status/1245632619661766657&#34;&gt;tweeted its handle&lt;/a&gt; (after a few hours there was a donut with score 222)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hdl.handle.net/10568/106899&#34;&gt;The second item&lt;/a&gt; now has a donut with score 2 since I &lt;a href=&#34;https://twitter.com/mralanorth/status/1243158045540134913&#34;&gt;tweeted its handle&lt;/a&gt; last week&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hdl.handle.net/10568/107258&#34;&gt;The third item&lt;/a&gt; now has a donut with score 1 since I &lt;a href=&#34;https://twitter.com/mralanorth/status/1243158786392625153&#34;&gt;tweeted it&lt;/a&gt; last week&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;On the same note, the &lt;a href=&#34;https://hdl.handle.net/10568/106573&#34;&gt;one item&lt;/a&gt; Abenet pointed out last week now has a donut with score of 104 after I &lt;a href=&#34;https://twitter.com/mralanorth/status/1243163710241345536&#34;&gt;tweeted it&lt;/a&gt; last week&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>March, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-03/</link>
      <pubDate>Mon, 02 Mar 2020 12:31:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-03/</guid>
      <description>&lt;h2 id=&#34;2020-03-02&#34;&gt;2020-03-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Update &lt;a href=&#34;https://github.com/ilri/dspace-statistics-api&#34;&gt;dspace-statistics-api&lt;/a&gt; for DSpace 6+ UUIDs&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Tag version 1.2.0 on GitHub&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Test migrating legacy Solr statistics to UUIDs with the as-of-yet unreleased &lt;a href=&#34;https://github.com/DSpace/DSpace/commit/184f2b2153479045fba6239342c63e7f8564b8b6#diff-0350ce2e13b28d5d61252b7a8f50a059&#34;&gt;SolrUpgradePre6xStatistics.java&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You need to download this into the DSpace 6.x source and compile it&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>February, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-02/</link>
      <pubDate>Sun, 02 Feb 2020 11:56:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-02/</guid>
      <description>&lt;h2 id=&#34;2020-02-02&#34;&gt;2020-02-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Continue working on porting CGSpace&amp;rsquo;s DSpace 5 code to DSpace 6.3 that I started yesterday&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Sign up for an account with MaxMind so I can get the GeoLite2-City.mmdb database&lt;/li&gt;&#xA;&lt;li&gt;I still need to wire up the API credentials and cron job into the Ansible infrastructure playbooks&lt;/li&gt;&#xA;&lt;li&gt;Fix some minor issues in the config and XMLUI themes, like removing Atmire stuff&lt;/li&gt;&#xA;&lt;li&gt;The code finally builds and runs with a fresh install&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>January, 2020</title>
      <link>http://localhost:1313/cgspace-notes/2020-01/</link>
      <pubDate>Mon, 06 Jan 2020 10:48:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2020-01/</guid>
      <description>&lt;h2 id=&#34;2020-01-06&#34;&gt;2020-01-06&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Open &lt;a href=&#34;https://tracker.atmire.com/tickets-cgiar-ilri/view-ticket?id=706&#34;&gt;a ticket&lt;/a&gt; with Atmire to request a quote for the upgrade to DSpace 6&lt;/li&gt;&#xA;&lt;li&gt;Last week Altmetric responded about the &lt;a href=&#34;https://hdl.handle.net/10568/97087&#34;&gt;item&lt;/a&gt; that had a lower score than than its DOI&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The score is now linked to the DOI&lt;/li&gt;&#xA;&lt;li&gt;Another &lt;a href=&#34;https://hdl.handle.net/10568/91278&#34;&gt;item&lt;/a&gt; that had the same problem in 2019 has now also linked to the score for its DOI&lt;/li&gt;&#xA;&lt;li&gt;Another &lt;a href=&#34;https://hdl.handle.net/10568/81236&#34;&gt;item&lt;/a&gt; that had the same problem in 2019 has also been fixed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2020-01-07&#34;&gt;2020-01-07&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Peter Ballantyne highlighted one more WLE &lt;a href=&#34;https://hdl.handle.net/10568/101286&#34;&gt;item&lt;/a&gt; that is missing the Altmetric score that its DOI has&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The DOI has a score of 259, but the Handle has no score at all&lt;/li&gt;&#xA;&lt;li&gt;I &lt;a href=&#34;https://twitter.com/mralanorth/status/1214471427157626881&#34;&gt;tweeted&lt;/a&gt; the CGSpace repository link&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>December, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-12/</link>
      <pubDate>Sun, 01 Dec 2019 11:22:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-12/</guid>
      <description>&lt;h2 id=&#34;2019-12-01&#34;&gt;2019-12-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Upgrade CGSpace (linode18) to Ubuntu 18.04:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Check any packages that have residual configs and purge them:&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;# dpkg -l | grep -E &#39;^rc&#39; | awk &#39;{print $2}&#39; | xargs dpkg -P&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;Make sure all packages are up to date and the package manager is up to date, then reboot:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# apt update &amp;amp;&amp;amp; apt full-upgrade&#xA;# apt-get autoremove &amp;amp;&amp;amp; apt-get autoclean&#xA;# dpkg -C&#xA;# reboot&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>November, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-11/</link>
      <pubDate>Mon, 04 Nov 2019 12:20:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-11/</guid>
      <description>&lt;h2 id=&#34;2019-11-04&#34;&gt;2019-11-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Peter noticed that there were 5.2 million hits on CGSpace in 2019-10 according to the Atmire usage statistics&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I looked in the nginx logs and see 4.6 million in the access logs, and 1.2 million in the API logs:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# zcat --force /var/log/nginx/*access.log.*.gz | grep -cE &amp;#34;[0-9]{1,2}/Oct/2019&amp;#34;&#xA;4671942&#xA;# zcat --force /var/log/nginx/{rest,oai,statistics}.log.*.gz | grep -cE &amp;#34;[0-9]{1,2}/Oct/2019&amp;#34;&#xA;1277694&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;So 4.6 million from XMLUI and another 1.2 million from API requests&lt;/li&gt;&#xA;&lt;li&gt;Let&amp;rsquo;s see how many of the REST API requests were for bitstreams (because they are counted in Solr stats):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# zcat --force /var/log/nginx/rest.log.*.gz | grep -c -E &amp;#34;[0-9]{1,2}/Oct/2019&amp;#34;&#xA;1183456 &#xA;# zcat --force /var/log/nginx/rest.log.*.gz | grep -E &amp;#34;[0-9]{1,2}/Oct/2019&amp;#34; | grep -c -E &amp;#34;/rest/bitstreams&amp;#34;&#xA;106781&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>October, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-10/</link>
      <pubDate>Tue, 01 Oct 2019 13:20:51 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-10/</guid>
      <description>&lt;h2 id=&#34;2019-10-01&#34;&gt;2019-10-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Udana from IWMI asked me for a CSV export of their community on CGSpace&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I exported it, but a quick run through the &lt;code&gt;csv-metadata-quality&lt;/code&gt; tool shows that there are some low-hanging fruits we can fix before I send him the data&lt;/li&gt;&#xA;&lt;li&gt;I will limit the scope to the titles, regions, subregions, and river basins for now to manually fix some non-breaking spaces (U+00A0) there that would otherwise be removed by the csv-metadata-quality script&amp;rsquo;s &amp;ldquo;unneccesary Unicode&amp;rdquo; fix:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ csvcut -c &amp;#39;id,dc.title[en_US],cg.coverage.region[en_US],cg.coverage.subregion[en_US],cg.river.basin[en_US]&amp;#39; ~/Downloads/10568-16814.csv &amp;gt; /tmp/iwmi-title-region-subregion-river.csv&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Then I replace them in vim with &lt;code&gt;:% s/\%u00a0/ /g&lt;/code&gt; because I can&amp;rsquo;t figure out the correct sed syntax to do it directly from the pipe above&lt;/li&gt;&#xA;&lt;li&gt;I uploaded those to CGSpace and then re-exported the metadata&lt;/li&gt;&#xA;&lt;li&gt;Now that I think about it, I shouldn&amp;rsquo;t be removing non-breaking spaces (U+00A0), I should be replacing them with normal spaces!&lt;/li&gt;&#xA;&lt;li&gt;I modified the script so it replaces the non-breaking spaces instead of removing them&lt;/li&gt;&#xA;&lt;li&gt;Then I ran the csv-metadata-quality script to do some general cleanups (though I temporarily commented out the whitespace fixes because it was too many thousands of rows):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ csv-metadata-quality -i ~/Downloads/10568-16814.csv -o /tmp/iwmi.csv -x &amp;#39;dc.date.issued,dc.date.issued[],dc.date.issued[en_US]&amp;#39; -u&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;That fixed 153 items (unnecessary Unicode, duplicates, comma–space fixes, etc)&lt;/li&gt;&#xA;&lt;li&gt;Release &lt;a href=&#34;https://github.com/ilri/csv-metadata-quality/releases/tag/v0.3.1&#34;&gt;version 0.3.1 of the csv-metadata-quality script&lt;/a&gt; with the non-breaking spaces change&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-03&#34;&gt;2019-10-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Upload the 117 IITA records that we had been working on last month (aka 20196th.xls aka Sept 6) to CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-04&#34;&gt;2019-10-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Create an account for Bioversity&amp;rsquo;s ICT consultant Francesco on DSpace Test:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ dspace user -a -m blah@mail.it -g Francesco -s Vernocchi -p &amp;#39;fffff&amp;#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Email Francesca and Carol to ask for follow up about the test upload I did on 2019-09-21&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I suggested that if they still want to do value addition of those records (like adding countries, regions, etc) that they could maybe do it after we migrate the records to CGSpace&lt;/li&gt;&#xA;&lt;li&gt;Carol responded to tell me where to map the items with type Brochure, Journal Item, and Thesis, so I applied them to the &lt;a href=&#34;https://dspacetest.cgiar.org/handle/10568/103688&#34;&gt;collection on DSpace Test&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-06&#34;&gt;2019-10-06&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hector from CCAFS responded about my feedback of their CLARISA API&#xA;&lt;ul&gt;&#xA;&lt;li&gt;He made some fixes to the metadata values they are using based on my feedback and said they are happy if we would use it&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Gabriela from CIP asked me if it was possible to generate an RSS feed of items that have the CIP subject &amp;ldquo;POTATO AGRI-FOOD SYSTEMS&amp;rdquo;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I notice that there is a similar term &amp;ldquo;SWEETPOTATO AGRI-FOOD SYSTEMS&amp;rdquo; so I had to come up with a way to exclude that using the boolean &amp;ldquo;AND NOT&amp;rdquo; in the &lt;a href=&#34;https://cgspace.cgiar.org/open-search/discover?query=cipsubject:POTATO%20AGRI%E2%80%90FOOD%20SYSTEMS%20AND%20NOT%20cipsubject:SWEETPOTATO%20AGRI%E2%80%90FOOD%20SYSTEMS&amp;amp;scope=10568/51671&amp;amp;sort_by=3&amp;amp;order=DESC&#34;&gt;OpenSearch query&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Again, the &lt;code&gt;sort_by=3&lt;/code&gt; parameter is the accession date, as configured in &lt;code&gt;dspace.cfg&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-08&#34;&gt;2019-10-08&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fix 108 more issues with authors in the ongoing Bioversity migration on DSpace Test, for example:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Europeanooperative Programme for Plant Genetic Resources&lt;/li&gt;&#xA;&lt;li&gt;Bioversity International. Capacity Development Unit&lt;/li&gt;&#xA;&lt;li&gt;W.M. van der Heide, W.M., Tripp, R.&lt;/li&gt;&#xA;&lt;li&gt;Internationallant Genetic Resources Institute&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Start looking at duplicates in the Bioversity migration data on DSpace Test&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I&amp;rsquo;m keeping track of the originals and duplicates in a Google Docs spreadsheet that I will share with Bioversity&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-09&#34;&gt;2019-10-09&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Continue working on identifying duplicates in the Bioversity migration&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I have been recording the originals and duplicates in a spreadsheet so I can map them later&lt;/li&gt;&#xA;&lt;li&gt;For now I am just reconciling any incorrect or missing metadata in the original items on CGSpace, deleting the duplicate from DSpace Test, and mapping the original to the correct place on CGSpace&lt;/li&gt;&#xA;&lt;li&gt;So far I have deleted thirty duplicates and mapped fourteen&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Run all system updates on DSpace Test (linode19) and reboot the server&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-10&#34;&gt;2019-10-10&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Felix Shaw from Earlham emailed me to ask about his admin account on DSpace Test&#xA;&lt;ul&gt;&#xA;&lt;li&gt;His old one got lost when I re-sync&amp;rsquo;d DSpace Test with CGSpace a few weeks ago&lt;/li&gt;&#xA;&lt;li&gt;I added a new account for him and added it to the Administrators group:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ dspace user -a -m wow@me.com -g Felix -s Shaw -p &amp;#39;fuananaaa&amp;#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;2019-10-11&#34;&gt;2019-10-11&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I ran the DSpace cleanup function on CGSpace and it found some errors:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ dspace cleanup -v&#xA;...&#xA;Error: ERROR: update or delete on table &amp;#34;bitstream&amp;#34; violates foreign key constraint &amp;#34;bundle_primary_bitstream_id_fkey&amp;#34; on table &amp;#34;bundle&amp;#34;&#xA;  Detail: Key (bitstream_id)=(171221) is still referenced from table &amp;#34;bundle&amp;#34;.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;The solution, as always, is (repeat as many times as needed):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# su - postgres&#xA;$ psql dspace -c &amp;#39;update bundle set primary_bitstream_id=NULL where primary_bitstream_id in (171221);&amp;#39;&#xA;UPDATE 1&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;2019-10-12&#34;&gt;2019-10-12&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;More work on identifying duplicates in the Bioversity migration data on DSpace Test&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I mapped twenty-five more items on CGSpace and deleted them from the migration test collection on DSpace Test&lt;/li&gt;&#xA;&lt;li&gt;After a few hours I think I finished all the duplicates that were identified by Atmire&amp;rsquo;s Duplicate Checker module&lt;/li&gt;&#xA;&lt;li&gt;According to my spreadsheet there were fifty-two in total&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I was preparing to check the affiliations on the Bioversity records when I noticed that the last list of top affiliations I generated has some anomalies&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I made some corrections in a CSV:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;from,to&#xA;CIAT,International Center for Tropical Agriculture&#xA;International Centre for Tropical Agriculture,International Center for Tropical Agriculture&#xA;International Maize and Wheat Improvement Center (CIMMYT),International Maize and Wheat Improvement Center&#xA;International Centre for Agricultural Research in the Dry Areas,International Center for Agricultural Research in the Dry Areas&#xA;International Maize and Wheat Improvement Centre,International Maize and Wheat Improvement Center&#xA;&amp;#34;Agricultural Information Resource Centre, Kenya.&amp;#34;,&amp;#34;Agricultural Information Resource Centre, Kenya&amp;#34;&#xA;&amp;#34;Centre for Livestock and Agricultural Development, Cambodia&amp;#34;,&amp;#34;Centre for Livestock and Agriculture Development, Cambodia&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Then I applied it with my &lt;code&gt;fix-metadata-values.py&lt;/code&gt; script on CGSpace:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ./fix-metadata-values.py -i /tmp/affiliations.csv -db dspace -u dspace -p &amp;#39;fuuu&amp;#39; -f from -m 211 -t to&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;I did some manual curation of about 300 authors in OpenRefine in preparation for telling Peter and Abenet that the migration is almost ready&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I would still like to perhaps (re)move institutional authors from &lt;code&gt;dc.contributor.author&lt;/code&gt; to &lt;code&gt;cg.contributor.affiliation&lt;/code&gt;, but I will have to run that by Francesca, Carol, and Abenet&lt;/li&gt;&#xA;&lt;li&gt;I could use a custom text facet like this in OpenRefine to find authors that likely match the &amp;ldquo;Last, F.&amp;rdquo; pattern: &lt;code&gt;isNotNull(value.match(/^.*, \p{Lu}\.?.*$/))&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;The &lt;code&gt;\p{Lu}&lt;/code&gt; is a cool &lt;a href=&#34;https://www.regular-expressions.info/unicode.html&#34;&gt;regex character class&lt;/a&gt; to make sure this works for letters with accents&lt;/li&gt;&#xA;&lt;li&gt;As cool as that is, it&amp;rsquo;s actually more effective to just search for authors that have &amp;ldquo;.&amp;rdquo; in them!&lt;/li&gt;&#xA;&lt;li&gt;I&amp;rsquo;ve decided to add a &lt;code&gt;cg.contributor.affiliation&lt;/code&gt; column to 1,025 items based on the logic above where the author name is not an actual person&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-13&#34;&gt;2019-10-13&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;More cleanup work on the authors in the Bioversity migration&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Now I sent the final feedback to Francesca, Carol, and Abenet&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Peter is still seeing some authors listed with &amp;ldquo;|&amp;rdquo; in the &amp;ldquo;Top Authors&amp;rdquo; statistics for some collections&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I looked in some of the items that are listed and the author field does not contain those invalid separators&lt;/li&gt;&#xA;&lt;li&gt;I decided to try doing a full Discovery re-indexing on CGSpace (linode18):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ time schedtool -B -e ionice -c2 -n7 nice -n19 dspace index-discovery -b&#xA;&#xA;real    82m35.993s&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;After the re-indexing the top authors still list the following:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Jagwe, J.|Ouma, E.A.|Brandes-van Dorresteijn, D.|Kawuma, Brian|Smith, J.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;I looked in the database to find authors that had &amp;ldquo;|&amp;rdquo; in them:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dspace=# SELECT text_value, resource_id FROM metadatavalue WHERE resource_type_id=2 AND metadata_field_id=3 AND text_value LIKE &amp;#39;%|%&amp;#39;;&#xA;            text_value            | resource_id &#xA;----------------------------------+-------------&#xA; Anandajayasekeram, P.|Puskur, R. |         157&#xA; Morales, J.|Renner, I.           |       22779&#xA; Zahid, A.|Haque, M.A.            |       25492&#xA;(3 rows)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Then I found their handles and corrected them, for example:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dspacetest=# select handle from item, handle where handle.resource_id = item.item_id AND item.item_id = &amp;#39;157&amp;#39; and handle.resource_type_id=2;&#xA;  handle   &#xA;-----------&#xA; 10568/129&#xA;(1 row)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;So I&amp;rsquo;m still not sure where these weird authors in the &amp;ldquo;Top Author&amp;rdquo; stats are coming from&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-14&#34;&gt;2019-10-14&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I talked to Peter about the Bioversity items and he said that we should add the institutional authors back to &lt;code&gt;dc.contributor.author&lt;/code&gt;, because I had moved them to &lt;code&gt;cg.contributor.affiliation&lt;/code&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Otherwise he said the data looks good&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-15&#34;&gt;2019-10-15&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I did a test export / import of the Bioversity migration items on DSpace Test&#xA;&lt;ul&gt;&#xA;&lt;li&gt;First export them:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ export JAVA_OPTS=&amp;#39;-Dfile.encoding=UTF-8 -Xmx512m&amp;#39;&#xA;$ mkdir 2019-10-15-Bioversity&#xA;$ dspace export -i 10568/108684 -t COLLECTION -m -n 0 -d 2019-10-15-Bioversity&#xA;$ sed -i &amp;#39;/&amp;lt;dcvalue element=&amp;#34;identifier&amp;#34; qualifier=&amp;#34;uri&amp;#34;&amp;gt;/d&amp;#39; 2019-10-15-Bioversity/*/dublin_core.xml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;It&amp;rsquo;s really stupid, but for some reason the handles are included even though I specified the &lt;code&gt;-m&lt;/code&gt; option, so after the export I removed the &lt;code&gt;dc.identifier.uri&lt;/code&gt; metadata values from the items&lt;/li&gt;&#xA;&lt;li&gt;Then I imported a test subset of them in my local test environment:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ~/dspace/bin/dspace import -a -c 10568/104049 -e fuu@cgiar.org -m 2019-10-15-Bioversity.map -s /tmp/2019-10-15-Bioversity&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;I had forgotten (again) that the &lt;code&gt;dspace export&lt;/code&gt; command doesn&amp;rsquo;t preserve collection ownership or mappings, so I will have to create a temporary collection on CGSpace to import these to, then do the mappings again after import&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;On CGSpace I will increase the RAM of the command line Java process for good luck before import&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ export JAVA_OPTS=&amp;#34;-Dfile.encoding=UTF-8 -Xmx1024m&amp;#34;&#xA;$ dspace import -a -c 10568/104057 -e fuu@cgiar.org -m 2019-10-15-Bioversity.map -s 2019-10-15-Bioversity&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;After importing the 1,367 items I re-exported the metadata, changed the owning collections to those based on their type, then re-imported them&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-21&#34;&gt;2019-10-21&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Re-sync the DSpace Test database and assetstore with CGSpace&lt;/li&gt;&#xA;&lt;li&gt;Run system updates on DSpace Test (linode19) and reboot it&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-24&#34;&gt;2019-10-24&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Create a test user for Mohammad Salem to test depositing from MEL to DSpace Test, as the last one I had created in 2019-08 was cleared when we re-syncronized DSpace Test with CGSpace recently.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-25&#34;&gt;2019-10-25&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Give a presentationa (via WebEx) about open source software to the ILRI Open Access Week&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The title was &lt;em&gt;Making ILRI code open: Software as an International Public Good&lt;/em&gt;&lt;/li&gt;&#xA;&lt;li&gt;It is available on CGSpace: &lt;a href=&#34;https://hdl.handle.net/10568/105514&#34;&gt;https://hdl.handle.net/10568/105514&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-28&#34;&gt;2019-10-28&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Move the CGSpace CG Core v2 notes from a &lt;a href=&#34;https://gist.github.com/alanorth/2db39e91f48d116e00a4edffd6ba6409&#34;&gt;GitHub Gist&lt;/a&gt; to a &lt;a href=&#34;http://localhost:1313/cgspace-notes/cgspace-cgcorev2-migration/&#34;&gt;page&lt;/a&gt; on this site for archive and searchability sake&lt;/li&gt;&#xA;&lt;li&gt;Work on the CG Core v2 implementation testing&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I noticed that the page title is messed up on the item view, and after over an hour of troubleshooting it I couldn&amp;rsquo;t figure out why&lt;/li&gt;&#xA;&lt;li&gt;It seems to be because the &lt;code&gt;dc.title&lt;/code&gt;→&lt;code&gt;dcterms.title&lt;/code&gt; modifications cause the title metadata to disappear from DRI&amp;rsquo;s &lt;code&gt;&amp;lt;pageMeta&amp;gt;&lt;/code&gt; and therefore the title is not accessible to the XSL transformation&lt;/li&gt;&#xA;&lt;li&gt;Also, I noticed a few places in the Java code where &lt;code&gt;dc.title&lt;/code&gt; is hard coded so I think this might be one of the fields that we just assume DSpace relies on internally&lt;/li&gt;&#xA;&lt;li&gt;I will revert all changes to &lt;code&gt;dc.title&lt;/code&gt; and &lt;code&gt;dc.title.alternative&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;TODO: there are similar issues with the &lt;code&gt;citation_author&lt;/code&gt; metadata element missing from DRI, so I might have to revert those changes too&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-10-29&#34;&gt;2019-10-29&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;After more digging in the source I found out why the &lt;code&gt;dcterms.title&lt;/code&gt; and &lt;code&gt;dcterms.creator&lt;/code&gt; fields are not present in the DRI &lt;code&gt;pageMeta&lt;/code&gt;&amp;hellip;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The &lt;code&gt;pageMeta&lt;/code&gt; element is constructed in &lt;code&gt;dspace-xmlui/src/main/java/org/dspace/app/xmlui/wing/IncludePageMeta.java&lt;/code&gt; and the code does not consider any other schemas besides DC&lt;/li&gt;&#xA;&lt;li&gt;I moved title and creator back to the original DC fields and then everything was working as expected in the pageMeta, so I guess we cannot use these in DCTERMS either!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Assist Maria from Bioversity with community and collection subscriptions&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>September, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-09/</link>
      <pubDate>Sun, 01 Sep 2019 10:17:51 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-09/</guid>
      <description>&lt;h2 id=&#34;2019-09-01&#34;&gt;2019-09-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Linode emailed to say that CGSpace (linode18) had a high rate of outbound traffic for several hours this morning&lt;/li&gt;&#xA;&lt;li&gt;Here are the top ten IPs in the nginx XMLUI and REST/OAI logs this morning:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# zcat --force /var/log/nginx/access.log /var/log/nginx/access.log.1 | grep -E &amp;#34;01/Sep/2019:0&amp;#34; | awk &amp;#39;{print $1}&amp;#39; | sort | uniq -c | sort -n | tail -n 10&#xA;    440 17.58.101.255&#xA;    441 157.55.39.101&#xA;    485 207.46.13.43&#xA;    728 169.60.128.125&#xA;    730 207.46.13.108&#xA;    758 157.55.39.9&#xA;    808 66.160.140.179&#xA;    814 207.46.13.212&#xA;   2472 163.172.71.23&#xA;   6092 3.94.211.189&#xA;# zcat --force /var/log/nginx/rest.log /var/log/nginx/rest.log.1 /var/log/nginx/oai.log /var/log/nginx/oai.log.1 | grep -E &amp;#34;01/Sep/2019:0&amp;#34; | awk &amp;#39;{print $1}&amp;#39; | sort | uniq -c | sort -n | tail -n 10&#xA;     33 2a01:7e00::f03c:91ff:fe16:fcb&#xA;     57 3.83.192.124&#xA;     57 3.87.77.25&#xA;     57 54.82.1.8&#xA;    822 2a01:9cc0:47:1:1a:4:0:2&#xA;   1223 45.5.184.72&#xA;   1633 172.104.229.92&#xA;   5112 205.186.128.185&#xA;   7249 2a01:7e00::f03c:91ff:fe18:7396&#xA;   9124 45.5.186.2&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>August, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-08/</link>
      <pubDate>Sat, 03 Aug 2019 12:39:51 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-08/</guid>
      <description>&lt;h2 id=&#34;2019-08-03&#34;&gt;2019-08-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Look at Bioversity&amp;rsquo;s latest migration CSV and now I see that Francesco has cleaned up the extra columns and the newline at the end of the file, but many of the column headers have an extra space in the name&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-08-04&#34;&gt;2019-08-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Deploy ORCID identifier updates requested by Bioversity to CGSpace&lt;/li&gt;&#xA;&lt;li&gt;Run system updates on CGSpace (linode18) and reboot it&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Before updating it I checked Solr and verified that all statistics cores were loaded properly&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;After rebooting, all statistics cores were loaded&amp;hellip; wow, that&amp;rsquo;s lucky.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Run system updates on DSpace Test (linode19) and reboot it&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>July, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-07/</link>
      <pubDate>Mon, 01 Jul 2019 12:13:51 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-07/</guid>
      <description>&lt;h2 id=&#34;2019-07-01&#34;&gt;2019-07-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Create an &amp;ldquo;AfricaRice books and book chapters&amp;rdquo; collection on CGSpace for AfricaRice&lt;/li&gt;&#xA;&lt;li&gt;Last month Sisay asked why the following &amp;ldquo;most popular&amp;rdquo; statistics link for a range of months in 2018 works for the CIAT community on DSpace Test, but not on CGSpace:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dspacetest.cgiar.org/handle/10568/35697/most-popular/item#simplefilter=custom&amp;amp;time_filter_end_date=01%2F12%2F2018&#34;&gt;DSpace Test&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cgspace.cgiar.org/handle/10568/35697/most-popular/item#simplefilter=custom&amp;amp;time_filter_end_date=01%2F12%2F2018&#34;&gt;CGSpace&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Abenet had another similar issue a few days ago when trying to find the stats for 2018 in the RTB community&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>June, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-06/</link>
      <pubDate>Sun, 02 Jun 2019 10:57:51 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-06/</guid>
      <description>&lt;h2 id=&#34;2019-06-02&#34;&gt;2019-06-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Merge the &lt;a href=&#34;https://github.com/ilri/DSpace/pull/425&#34;&gt;Solr filterCache&lt;/a&gt; and &lt;a href=&#34;https://github.com/ilri/DSpace/pull/426&#34;&gt;XMLUI ISI journal&lt;/a&gt; changes to the &lt;code&gt;5_x-prod&lt;/code&gt; branch and deploy on CGSpace&lt;/li&gt;&#xA;&lt;li&gt;Run system updates on CGSpace (linode18) and reboot it&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2019-06-03&#34;&gt;2019-06-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Skype with Marie-Angélique and Abenet about &lt;a href=&#34;https://agriculturalsemantics.github.io/cg-core/cgcore.html&#34;&gt;CG Core v2&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>May, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-05/</link>
      <pubDate>Wed, 01 May 2019 07:37:43 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-05/</guid>
      <description>&lt;h2 id=&#34;2019-05-01&#34;&gt;2019-05-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Help CCAFS with regenerating some item thumbnails after they uploaded new PDFs to some items on CGSpace&lt;/li&gt;&#xA;&lt;li&gt;A user on the dspace-tech mailing list offered some suggestions for troubleshooting the problem with the inability to delete certain items&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Apparently if the item is in the &lt;code&gt;workflowitem&lt;/code&gt; table it is submitted to a workflow&lt;/li&gt;&#xA;&lt;li&gt;And if it is in the &lt;code&gt;workspaceitem&lt;/code&gt; table it is in the pre-submitted state&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;The item seems to be in a pre-submitted state, so I tried to delete it from there:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dspace=# DELETE FROM workspaceitem WHERE item_id=74648;&#xA;DELETE 1&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;But after this I tried to delete the item from the XMLUI and it is &lt;em&gt;still&lt;/em&gt; present&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-04/</link>
      <pubDate>Mon, 01 Apr 2019 09:00:43 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-04/</guid>
      <description>&lt;h2 id=&#34;2019-04-01&#34;&gt;2019-04-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Meeting with AgroKnow to discuss CGSpace, ILRI data, AReS, GARDIAN, etc&#xA;&lt;ul&gt;&#xA;&lt;li&gt;They asked if we had plans to enable RDF support in CGSpace&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;There have been 4,400 more downloads of the CTA Spore publication from those strange Amazon IP addresses today&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I suspected that some might not be successful, because the stats show less, but today they were all HTTP 200!&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# cat /var/log/nginx/access.log /var/log/nginx/access.log.1 | grep &amp;#39;Spore-192-EN-web.pdf&amp;#39; | grep -E &amp;#39;(18.196.196.108|18.195.78.144|18.195.218.6)&amp;#39; | awk &amp;#39;{print $9}&amp;#39; | sort | uniq -c | sort -n | tail -n 5&#xA;   4432 200&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;In the last two weeks there have been 47,000 downloads of this &lt;em&gt;same exact PDF&lt;/em&gt; by these three IP addresses&lt;/li&gt;&#xA;&lt;li&gt;Apply country and region corrections and deletions on DSpace Test and CGSpace:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ./fix-metadata-values.py -i /tmp/2019-02-21-fix-9-countries.csv -db dspace -u dspace -p &amp;#39;fuuu&amp;#39; -f cg.coverage.country -m 228 -t ACTION -d&#xA;$ ./fix-metadata-values.py -i /tmp/2019-02-21-fix-4-regions.csv -db dspace -u dspace -p &amp;#39;fuuu&amp;#39; -f cg.coverage.region -m 231 -t action -d&#xA;$ ./delete-metadata-values.py -i /tmp/2019-02-21-delete-2-countries.csv -db dspace -u dspace -p &amp;#39;fuuu&amp;#39; -m 228 -f cg.coverage.country -d&#xA;$ ./delete-metadata-values.py -i /tmp/2019-02-21-delete-1-region.csv -db dspace -u dspace -p &amp;#39;fuuu&amp;#39; -m 231 -f cg.coverage.region -d&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>March, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-03/</link>
      <pubDate>Fri, 01 Mar 2019 12:16:30 +0100</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-03/</guid>
      <description>&lt;h2 id=&#34;2019-03-01&#34;&gt;2019-03-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I checked IITA&amp;rsquo;s 259 Feb 14 records from last month for duplicates using Atmire&amp;rsquo;s Duplicate Checker on a fresh snapshot of CGSpace on my local machine and everything looks good&lt;/li&gt;&#xA;&lt;li&gt;I am now only waiting to hear from her about where the items should go, though I assume Journal Articles go to IITA Journal Articles collection, etc&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;Looking at the other half of Udana&amp;rsquo;s WLE records from 2018-11&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I finished the ones for Restoring Degraded Landscapes (RDL), but these are for Variability, Risks and Competing Uses (VRC)&lt;/li&gt;&#xA;&lt;li&gt;I did the usual cleanups for whitespace, added regions where they made sense for certain countries, cleaned up the DOI link formats, added rights information based on the publications page for a few items&lt;/li&gt;&#xA;&lt;li&gt;Most worryingly, there are encoding errors in the abstracts for eleven items, for example:&lt;/li&gt;&#xA;&lt;li&gt;68.15% � 9.45 instead of 68.15% ± 9.45&lt;/li&gt;&#xA;&lt;li&gt;2003�2013 instead of 2003–2013&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I think I will need to ask Udana to re-copy and paste the abstracts with more care using Google Docs&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>February, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-02/</link>
      <pubDate>Fri, 01 Feb 2019 21:37:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-02/</guid>
      <description>&lt;h2 id=&#34;2019-02-01&#34;&gt;2019-02-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Linode has alerted a few times since last night that the CPU usage on CGSpace (linode18) was high despite me increasing the alert threshold last week from 250% to 275%—I might need to increase it again!&lt;/li&gt;&#xA;&lt;li&gt;The top IPs before, during, and after this latest alert tonight were:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# zcat --force /var/log/nginx/*.log /var/log/nginx/*.log.1 | grep -E &amp;#34;01/Feb/2019:(17|18|19|20|21)&amp;#34; | awk &amp;#39;{print $1}&amp;#39; | sort | uniq -c | sort -n | tail -n 10&#xA;    245 207.46.13.5&#xA;    332 54.70.40.11&#xA;    385 5.143.231.38&#xA;    405 207.46.13.173&#xA;    405 207.46.13.75&#xA;   1117 66.249.66.219&#xA;   1121 35.237.175.180&#xA;   1546 5.9.6.51&#xA;   2474 45.5.186.2&#xA;   5490 85.25.237.71&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;85.25.237.71&lt;/code&gt; is the &amp;ldquo;Linguee Bot&amp;rdquo; that I first saw last month&lt;/li&gt;&#xA;&lt;li&gt;The Solr statistics the past few months have been very high and I was wondering if the web server logs also showed an increase&lt;/li&gt;&#xA;&lt;li&gt;There were just over 3 million accesses in the nginx logs last month:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# time zcat --force /var/log/nginx/* | grep -cE &amp;#34;[0-9]{1,2}/Jan/2019&amp;#34;&#xA;3018243&#xA;&#xA;real    0m19.873s&#xA;user    0m22.203s&#xA;sys     0m1.979s&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>January, 2019</title>
      <link>http://localhost:1313/cgspace-notes/2019-01/</link>
      <pubDate>Wed, 02 Jan 2019 09:48:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2019-01/</guid>
      <description>&lt;h2 id=&#34;2019-01-02&#34;&gt;2019-01-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Linode alerted that CGSpace (linode18) had a higher outbound traffic rate than normal early this morning&lt;/li&gt;&#xA;&lt;li&gt;I don&amp;rsquo;t see anything interesting in the web server logs around that time though:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# zcat --force /var/log/nginx/*.log /var/log/nginx/*.log.1 | grep -E &amp;#34;02/Jan/2019:0(1|2|3)&amp;#34; | awk &amp;#39;{print $1}&amp;#39; | sort | uniq -c | sort -n | tail -n 10&#xA;     92 40.77.167.4&#xA;     99 210.7.29.100&#xA;    120 38.126.157.45&#xA;    177 35.237.175.180&#xA;    177 40.77.167.32&#xA;    216 66.249.75.219&#xA;    225 18.203.76.93&#xA;    261 46.101.86.248&#xA;    357 207.46.13.1&#xA;    903 54.70.40.11&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>December, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-12/</link>
      <pubDate>Sun, 02 Dec 2018 02:09:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-12/</guid>
      <description>&lt;h2 id=&#34;2018-12-01&#34;&gt;2018-12-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Switch CGSpace (linode18) to use OpenJDK instead of Oracle JDK&lt;/li&gt;&#xA;&lt;li&gt;I manually installed OpenJDK, then removed Oracle JDK, then re-ran the &lt;a href=&#34;http://github.com/ilri/rmg-ansible-public&#34;&gt;Ansible playbook&lt;/a&gt; to update all configuration files, etc&lt;/li&gt;&#xA;&lt;li&gt;Then I ran all system updates and restarted the server&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2018-12-02&#34;&gt;2018-12-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I noticed that there is another issue with PDF thumbnails on CGSpace, and I see there was another &lt;a href=&#34;https://usn.ubuntu.com/3831-1/&#34;&gt;Ghostscript vulnerability last week&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>November, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-11/</link>
      <pubDate>Thu, 01 Nov 2018 16:41:30 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-11/</guid>
      <description>&lt;h2 id=&#34;2018-11-01&#34;&gt;2018-11-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Finalize AReS Phase I and Phase II ToRs&lt;/li&gt;&#xA;&lt;li&gt;Send a note about my &lt;a href=&#34;https://github.com/ilri/dspace-statistics-api&#34;&gt;dspace-statistics-api&lt;/a&gt; to the dspace-tech mailing list&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2018-11-03&#34;&gt;2018-11-03&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Linode has been sending mails a few times a day recently that CGSpace (linode18) has had high CPU usage&lt;/li&gt;&#xA;&lt;li&gt;Today these are the top 10 IPs:&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>October, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-10/</link>
      <pubDate>Mon, 01 Oct 2018 22:31:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-10/</guid>
      <description>&lt;h2 id=&#34;2018-10-01&#34;&gt;2018-10-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Phil Thornton got an ORCID identifier so we need to add it to the list on CGSpace and tag his existing items&lt;/li&gt;&#xA;&lt;li&gt;I created a GitHub issue to track this &lt;a href=&#34;https://github.com/ilri/DSpace/issues/389&#34;&gt;#389&lt;/a&gt;, because I&amp;rsquo;m super busy in Nairobi right now&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>September, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-09/</link>
      <pubDate>Sun, 02 Sep 2018 09:55:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-09/</guid>
      <description>&lt;h2 id=&#34;2018-09-02&#34;&gt;2018-09-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;New &lt;a href=&#34;https://jdbc.postgresql.org/documentation/changelog.html#version_42.2.5&#34;&gt;PostgreSQL JDBC driver version 42.2.5&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;I&amp;rsquo;ll update the DSpace role in our &lt;a href=&#34;https://github.com/ilri/rmg-ansible-public&#34;&gt;Ansible infrastructure playbooks&lt;/a&gt; and run the updated playbooks on CGSpace and DSpace Test&lt;/li&gt;&#xA;&lt;li&gt;Also, I&amp;rsquo;ll re-run the &lt;code&gt;postgresql&lt;/code&gt; tasks because the custom PostgreSQL variables are dynamic according to the system&amp;rsquo;s RAM, and we never re-ran them after migrating to larger Linodes last month&lt;/li&gt;&#xA;&lt;li&gt;I&amp;rsquo;m testing the new DSpace 5.8 branch in my Ubuntu 18.04 environment and I&amp;rsquo;m getting those autowire errors in Tomcat 8.5.30 again:&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>August, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-08/</link>
      <pubDate>Wed, 01 Aug 2018 11:52:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-08/</guid>
      <description>&lt;h2 id=&#34;2018-08-01&#34;&gt;2018-08-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;DSpace Test had crashed at some point yesterday morning and I see the following in &lt;code&gt;dmesg&lt;/code&gt;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;[Tue Jul 31 00:00:41 2018] Out of memory: Kill process 1394 (java) score 668 or sacrifice child&#xA;[Tue Jul 31 00:00:41 2018] Killed process 1394 (java) total-vm:15601860kB, anon-rss:5355528kB, file-rss:0kB, shmem-rss:0kB&#xA;[Tue Jul 31 00:00:41 2018] oom_reaper: reaped process 1394 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Judging from the time of the crash it was probably related to the Discovery indexing that starts at midnight&lt;/li&gt;&#xA;&lt;li&gt;From the DSpace log I see that eventually Solr stopped responding, so I guess the &lt;code&gt;java&lt;/code&gt; process that was OOM killed above was Tomcat&amp;rsquo;s&lt;/li&gt;&#xA;&lt;li&gt;I&amp;rsquo;m not sure why Tomcat didn&amp;rsquo;t crash with an OutOfMemoryError&amp;hellip;&lt;/li&gt;&#xA;&lt;li&gt;Anyways, perhaps I should increase the JVM heap from 5120m to 6144m like we did a few months ago when we tried to run the whole CGSpace Solr core&lt;/li&gt;&#xA;&lt;li&gt;The server only has 8GB of RAM so we&amp;rsquo;ll eventually need to upgrade to a larger one because we&amp;rsquo;ll start starving the OS, PostgreSQL, and command line batch processes&lt;/li&gt;&#xA;&lt;li&gt;I ran all system updates on DSpace Test and rebooted it&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>July, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-07/</link>
      <pubDate>Sun, 01 Jul 2018 12:56:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-07/</guid>
      <description>&lt;h2 id=&#34;2018-07-01&#34;&gt;2018-07-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I want to upgrade DSpace Test to DSpace 5.8 so I took a backup of its current database just in case:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ pg_dump -b -v -o --format=custom -U dspace -f dspace-2018-07-01.backup dspace&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;During the &lt;code&gt;mvn package&lt;/code&gt; stage on the 5.8 branch I kept getting issues with java running out of memory:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;There is insufficient memory for the Java Runtime Environment to continue.&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>June, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-06/</link>
      <pubDate>Mon, 04 Jun 2018 19:49:54 -0700</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-06/</guid>
      <description>&lt;h2 id=&#34;2018-06-04&#34;&gt;2018-06-04&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Test the &lt;a href=&#34;https://tracker.atmire.com/tickets-cgiar-ilri/view-ticket?id=560&#34;&gt;DSpace 5.8 module upgrades from Atmire&lt;/a&gt; (&lt;a href=&#34;https://github.com/ilri/DSpace/pull/378&#34;&gt;#378&lt;/a&gt;)&#xA;&lt;ul&gt;&#xA;&lt;li&gt;There seems to be a problem with the CUA and L&amp;amp;R versions in &lt;code&gt;pom.xml&lt;/code&gt; because they are using SNAPSHOT and it doesn&amp;rsquo;t build&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;I added the new CCAFS Phase II Project Tag &lt;code&gt;PII-FP1_PACCA2&lt;/code&gt; and merged it into the &lt;code&gt;5_x-prod&lt;/code&gt; branch (&lt;a href=&#34;https://github.com/ilri/DSpace/pull/379&#34;&gt;#379&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;li&gt;I proofed and tested the ILRI author corrections that Peter sent back to me this week:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ ./fix-metadata-values.py -i /tmp/2018-05-30-Correct-660-authors.csv -db dspace -u dspace -p &amp;#39;fuuu&amp;#39; -f dc.contributor.author -t correct -m 3 -n&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;I think a sane proofing workflow in OpenRefine is to apply the custom text facets for check/delete/remove and illegal characters that I developed in &lt;a href=&#34;http://localhost:1313/cgspace-notes/2018-03/&#34;&gt;March, 2018&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Time to index ~70,000 items on CGSpace:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ time schedtool -D -e ionice -c2 -n7 nice -n19 [dspace]/bin/dspace index-discovery -b                                  &#xA;&#xA;real    74m42.646s&#xA;user    8m5.056s&#xA;sys     2m7.289s&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>May, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-05/</link>
      <pubDate>Tue, 01 May 2018 16:43:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-05/</guid>
      <description>&lt;h2 id=&#34;2018-05-01&#34;&gt;2018-05-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I cleared the Solr statistics core on DSpace Test by issuing two commands directly to the Solr admin interface:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;http://localhost:3000/solr/statistics/update?stream.body=%3Cdelete%3E%3Cquery%3E*:*%3C/query%3E%3C/delete%3E&lt;/li&gt;&#xA;&lt;li&gt;http://localhost:3000/solr/statistics/update?stream.body=%3Ccommit/%3E&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Then I reduced the JVM heap size from 6144 back to 5120m&lt;/li&gt;&#xA;&lt;li&gt;Also, I switched it to use OpenJDK instead of Oracle Java, as well as re-worked the &lt;a href=&#34;https://github.com/ilri/rmg-ansible-public&#34;&gt;Ansible infrastructure scripts&lt;/a&gt; to support hosts choosing which distribution they want to use&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>April, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-04/</link>
      <pubDate>Sun, 01 Apr 2018 16:13:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-04/</guid>
      <description>&lt;h2 id=&#34;2018-04-01&#34;&gt;2018-04-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;I tried to test something on DSpace Test but noticed that it&amp;rsquo;s down since god knows when&lt;/li&gt;&#xA;&lt;li&gt;Catalina logs at least show some memory errors yesterday:&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>March, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-03/</link>
      <pubDate>Fri, 02 Mar 2018 16:07:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-03/</guid>
      <description>&lt;h2 id=&#34;2018-03-02&#34;&gt;2018-03-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Export a CSV of the IITA community metadata for Martin Mueller&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>February, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-02/</link>
      <pubDate>Thu, 01 Feb 2018 16:28:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-02/</guid>
      <description>&lt;h2 id=&#34;2018-02-01&#34;&gt;2018-02-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Peter gave feedback on the &lt;code&gt;dc.rights&lt;/code&gt; proof of concept that I had sent him last week&lt;/li&gt;&#xA;&lt;li&gt;We don&amp;rsquo;t need to distinguish between internal and external works, so that makes it just a simple list&lt;/li&gt;&#xA;&lt;li&gt;Yesterday I figured out how to monitor DSpace sessions using JMX&lt;/li&gt;&#xA;&lt;li&gt;I copied the logic in the &lt;code&gt;jmx_tomcat_dbpools&lt;/code&gt; provided by Ubuntu&amp;rsquo;s &lt;code&gt;munin-plugins-java&lt;/code&gt; package and used the stuff I discovered about JMX &lt;a href=&#34;http://localhost:1313/cgspace-notes/2018-01/&#34;&gt;in 2018-01&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>January, 2018</title>
      <link>http://localhost:1313/cgspace-notes/2018-01/</link>
      <pubDate>Tue, 02 Jan 2018 08:35:54 -0800</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2018-01/</guid>
      <description>&lt;h2 id=&#34;2018-01-02&#34;&gt;2018-01-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Uptime Robot noticed that CGSpace went down and up a few times last night, for a few minutes each time&lt;/li&gt;&#xA;&lt;li&gt;I didn&amp;rsquo;t get any load alerts from Linode and the REST and XMLUI logs don&amp;rsquo;t show anything out of the ordinary&lt;/li&gt;&#xA;&lt;li&gt;The nginx logs show HTTP 200s until &lt;code&gt;02/Jan/2018:11:27:17 +0000&lt;/code&gt; when Uptime Robot got an HTTP 500&lt;/li&gt;&#xA;&lt;li&gt;In dspace.log around that time I see many errors like &amp;ldquo;Client closed the connection before file download was complete&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;And just before that I see this:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Caused by: org.apache.tomcat.jdbc.pool.PoolExhaustedException: [http-bio-127.0.0.1-8443-exec-980] Timeout: Pool empty. Unable to fetch a connection in 5 seconds, none available[size:50; busy:50; idle:0; lastwait:5000].&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Ah hah! So the pool was actually empty!&lt;/li&gt;&#xA;&lt;li&gt;I need to increase that, let&amp;rsquo;s try to bump it up from 50 to 75&lt;/li&gt;&#xA;&lt;li&gt;After that one client got an HTTP 499 but then the rest were HTTP 200, so I don&amp;rsquo;t know what the hell Uptime Robot saw&lt;/li&gt;&#xA;&lt;li&gt;I notice this error quite a few times in dspace.log:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;2018-01-02 01:21:19,137 ERROR org.dspace.app.xmlui.aspect.discovery.SidebarFacetsTransformer @ Error while searching for sidebar facets&#xA;org.dspace.discovery.SearchServiceException: org.apache.solr.search.SyntaxError: Cannot parse &amp;#39;dateIssued_keyword:[1976+TO+1979]&amp;#39;: Encountered &amp;#34; &amp;#34;]&amp;#34; &amp;#34;] &amp;#34;&amp;#34; at line 1, column 32.&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;And there are many of these errors every day for the past month:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ grep -c &amp;#34;Error while searching for sidebar facets&amp;#34; dspace.log.*&#xA;dspace.log.2017-11-21:4&#xA;dspace.log.2017-11-22:1&#xA;dspace.log.2017-11-23:4&#xA;dspace.log.2017-11-24:11&#xA;dspace.log.2017-11-25:0&#xA;dspace.log.2017-11-26:1&#xA;dspace.log.2017-11-27:7&#xA;dspace.log.2017-11-28:21&#xA;dspace.log.2017-11-29:31&#xA;dspace.log.2017-11-30:15&#xA;dspace.log.2017-12-01:15&#xA;dspace.log.2017-12-02:20&#xA;dspace.log.2017-12-03:38&#xA;dspace.log.2017-12-04:65&#xA;dspace.log.2017-12-05:43&#xA;dspace.log.2017-12-06:72&#xA;dspace.log.2017-12-07:27&#xA;dspace.log.2017-12-08:15&#xA;dspace.log.2017-12-09:29&#xA;dspace.log.2017-12-10:35&#xA;dspace.log.2017-12-11:20&#xA;dspace.log.2017-12-12:44&#xA;dspace.log.2017-12-13:36&#xA;dspace.log.2017-12-14:59&#xA;dspace.log.2017-12-15:104&#xA;dspace.log.2017-12-16:53&#xA;dspace.log.2017-12-17:66&#xA;dspace.log.2017-12-18:83&#xA;dspace.log.2017-12-19:101&#xA;dspace.log.2017-12-20:74&#xA;dspace.log.2017-12-21:55&#xA;dspace.log.2017-12-22:66&#xA;dspace.log.2017-12-23:50&#xA;dspace.log.2017-12-24:85&#xA;dspace.log.2017-12-25:62&#xA;dspace.log.2017-12-26:49&#xA;dspace.log.2017-12-27:30&#xA;dspace.log.2017-12-28:54&#xA;dspace.log.2017-12-29:68&#xA;dspace.log.2017-12-30:89&#xA;dspace.log.2017-12-31:53&#xA;dspace.log.2018-01-01:45&#xA;dspace.log.2018-01-02:34&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Danny wrote to ask for help renewing the wildcard ilri.org certificate and I advised that we should probably use Let&amp;rsquo;s Encrypt if it&amp;rsquo;s just a handful of domains&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>December, 2017</title>
      <link>http://localhost:1313/cgspace-notes/2017-12/</link>
      <pubDate>Fri, 01 Dec 2017 13:53:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2017-12/</guid>
      <description>&lt;h2 id=&#34;2017-12-01&#34;&gt;2017-12-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Uptime Robot noticed that CGSpace went down&lt;/li&gt;&#xA;&lt;li&gt;The logs say &amp;ldquo;Timeout waiting for idle object&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;PostgreSQL activity says there are 115 connections currently&lt;/li&gt;&#xA;&lt;li&gt;The list of connections to XMLUI and REST API for today:&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>November, 2017</title>
      <link>http://localhost:1313/cgspace-notes/2017-11/</link>
      <pubDate>Thu, 02 Nov 2017 09:37:54 +0200</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2017-11/</guid>
      <description>&lt;h2 id=&#34;2017-11-01&#34;&gt;2017-11-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The CORE developers responded to say they are looking into their bot not respecting our robots.txt&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;2017-11-02&#34;&gt;2017-11-02&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Today there have been no hits by CORE and no alerts from Linode (coincidence?)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# grep -c &amp;#34;CORE&amp;#34; /var/log/nginx/access.log&#xA;0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;Generate list of authors on CGSpace for Peter to go through and correct:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;dspace=# \copy (select distinct text_value, count(*) as count from metadatavalue where metadata_field_id = (select metadata_field_id from metadatafieldregistry where element = &amp;#39;contributor&amp;#39; and qualifier = &amp;#39;author&amp;#39;) AND resource_type_id = 2 group by text_value order by count desc) to /tmp/authors.csv with csv;&#xA;COPY 54701&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>October, 2017</title>
      <link>http://localhost:1313/cgspace-notes/2017-10/</link>
      <pubDate>Sun, 01 Oct 2017 08:07:54 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/2017-10/</guid>
      <description>&lt;h2 id=&#34;2017-10-01&#34;&gt;2017-10-01&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Peter emailed to point out that many items in the &lt;a href=&#34;https://cgspace.cgiar.org/handle/10568/2703&#34;&gt;ILRI archive collection&lt;/a&gt; have multiple handles:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;http://hdl.handle.net/10568/78495||http://hdl.handle.net/10568/79336&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;&#xA;&lt;li&gt;There appears to be a pattern but I&amp;rsquo;ll have to look a bit closer and try to clean them up automatically, either in SQL or in OpenRefine&lt;/li&gt;&#xA;&lt;li&gt;Add Katherine Lutz to the groups for content submission and edit steps of the CGIAR System collections&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>CGIAR Library Migration</title>
      <link>http://localhost:1313/cgspace-notes/cgiar-library-migration/</link>
      <pubDate>Mon, 18 Sep 2017 16:38:35 +0300</pubDate>
      <guid>http://localhost:1313/cgspace-notes/cgiar-library-migration/</guid>
      <description>&lt;p&gt;Rough notes for importing the CGIAR Library content. It was decided that this content would go to a new top-level community called &lt;em&gt;CGIAR System Organization&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
